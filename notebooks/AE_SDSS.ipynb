{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/VMBoehm/SDSS_PAE/blob/main/LSTM_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqDqXXTQ1FMN"
   },
   "source": [
    "# Template and tests for an LSTM Auto-Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZcR4zT3V8dMc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///global/homes/v/vboehm/codes/SDSS_PAE\n",
      "Requirement already satisfied: astropy in /global/u2/v/vboehm/.local/lib/python3.8/site-packages (from sdss-pae==0.1.0) (4.2.1)\n",
      "Requirement already satisfied: numpy in /global/common/cori_cle7/software/jupyter/cgpu/21-03/lib/python3.8/site-packages (from sdss-pae==0.1.0) (1.20.2)\n",
      "Requirement already satisfied: pyerfa in /global/u2/v/vboehm/.local/lib/python3.8/site-packages (from astropy->sdss-pae==0.1.0) (1.7.3)\n",
      "Installing collected packages: sdss-pae\n",
      "  Attempting uninstall: sdss-pae\n",
      "    Found existing installation: sdss-pae 0.1.0\n",
      "    Uninstalling sdss-pae-0.1.0:\n",
      "      Successfully uninstalled sdss-pae-0.1.0\n",
      "  Running setup.py develop for sdss-pae\n",
      "Successfully installed sdss-pae\n"
     ]
    }
   ],
   "source": [
    "# ! pip install tensorflow-probability==0.11.0\n",
    "! pip install --user -e /global/homes/v/vboehm/codes/SDSS_PAE/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Layer, Reshape, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, UpSampling1D, AveragePooling1D\n",
    "from tensorflow.keras.layers import RepeatVector, Conv2DTranspose, Flatten\n",
    "from tensorflow.keras.layers import TimeDistributed, Input, Lambda, Masking, Dropout\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1DTranspose(input_tensor, filters, kernel_size, strides=2, padding='valid', output_padding=0, name=None):\n",
    "    \"\"\"\n",
    "        input_tensor: tensor, with the shape (batch_size, time_steps, dims)\n",
    "        filters: int, output dimension, i.e. the output tensor will have the shape of (batch_size, time_steps, filters)\n",
    "        kernel_size: int, size of the convolution kernel\n",
    "        strides: int, convolution step size\n",
    "        padding: 'same' | 'valid'\n",
    "    \"\"\"\n",
    "    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1), padding=padding, output_padding=(output_padding,0), name=name)(x)\n",
    "    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings\n",
    "# user defined span (following Yip et al and Portillo et al)\n",
    "root_models     = '/global/cscratch1/sd/vboehm/Models/SDSS_AE/'\n",
    "\n",
    "root_encoded    = '/global/cscratch1/sd/vboehm/Datasets/encoded/sdss/'\n",
    "root_decoded    = '/global/cscratch1/sd/vboehm/Datasets/decoded/sdss/'\n",
    "root_data       = '/global/cscratch1/sd/vboehm/Datasets'\n",
    "\n",
    "root_prepped    = os.path.join(root_data,'sdss/prepped')\n",
    "\n",
    "wlmin, wlmax    = (3388,8318)\n",
    "fixed_num_bins  = 1000\n",
    "\n",
    "label           = 'galaxies_quasars_bins1000_wl3388-8318'\n",
    "label_          = label+'_minz005_maxz036_minSN50'\n",
    "label_2         = label+'_minz01_maxz036_minSN50'+'_8_fully_connected_xlarge_std_one_batch'\n",
    "\n",
    "seed            = 8720\n",
    "\n",
    "latent_dim      = 8\n",
    "network_type    = 'fully_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_range      = (np.log10(wlmin),np.log10(wlmax))\n",
    "# new binning \n",
    "new_wl        = np.logspace(wl_range[0],wl_range[1],fixed_num_bins+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data and join\n",
    "res_fluxes, res_masks, res_inv_vars = [], [] ,[]\n",
    "redshifts, SNs, ras, decs, category, sublabel = [], [], [], [], [], []\n",
    "for nn in range(1,4):\n",
    "    res_fluxes_, res_masks_, res_inv_vars_ = np.load(os.path.join(root_prepped,'prepped_data_spectra_%s_batch%d.npy'%(label_,nn)))\n",
    "    redshifts_, SNs_, ras_, decs_, category_, sublabel_ =  np.load(os.path.join(root_prepped,'prepped_data_prop_%s_batch%d.npy'%(label_,nn)))\n",
    "    if nn==1:\n",
    "        res_fluxes, res_masks, res_inv_vars, redshifts, SNs, ras, decs, category, sublabel = res_fluxes_, res_masks_, res_inv_vars_, redshifts_, SNs_, ras_, decs_, category_, sublabel_\n",
    "    else:\n",
    "        res_fluxes   = np.concatenate([res_fluxes, res_fluxes_],axis=0)\n",
    "        res_masks    = np.concatenate([res_masks, res_masks_],axis=0)\n",
    "        res_inv_vars = np.concatenate([res_inv_vars, res_inv_vars_],axis=0)\n",
    "        redshifts    = np.concatenate([redshifts, redshifts_],axis=0)\n",
    "        SNs          = np.concatenate([SNs, SNs_],axis=0)\n",
    "        ras          = np.concatenate([ras, ras_],axis=0)\n",
    "        decs         = np.concatenate([decs, decs_],axis=0)\n",
    "        category     = np.concatenate([category, category_],axis=0)\n",
    "        sublabel     = np.concatenate([sublabel, sublabel_],axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = fixed_num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0sQyEd6-dhq",
    "outputId": "8e9b7513-56a3-4bea-bbc6-34c587a4f6d4"
   },
   "outputs": [],
   "source": [
    "class bottleneck(Layer):\n",
    "    def __init__(self, units, dim, **kwargs):\n",
    "        self.units  = units\n",
    "        self.dim    = dim\n",
    "        self.LSTM1  = LSTM(units[0],  return_sequences=True)\n",
    "        self.LSTM2  = LSTM(units[1],  return_sequences=False)\n",
    "        self.Repeat = RepeatVector(dim)\n",
    "        super(bottleneck, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.Repeat(self.LSTM2(self.LSTM1(inputs)))\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "input        = Input(shape=(dim,1))\n",
    "input_params = Input(shape=(1))\n",
    "input_mask   = Input(shape=(dim,1))\n",
    "input_noise  = Input(shape=(dim,1))\n",
    "\n",
    "\n",
    "if network_type=='fully_connected':\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(512)(x)\n",
    "    #x = BatchNormalization(trainable=False)(x)\n",
    "    x = Dense(256)(x)\n",
    "    #x = BatchNormalization(trainable=False)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization(trainable=False)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dense(16)(x)\n",
    "    #x = BatchNormalization(trainable=False)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dense(latent_dim)(x)  \n",
    "    #x = tf.concat([x,input_params],axis=1)\n",
    "    #z = Flatten()(input_params)\n",
    "    #x = tf.concat([input_params,x], axis=1)\n",
    "    x = Dense(16)(x)\n",
    "    x = BatchNormalization(trainable=False)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dense(64)(x)\n",
    "    #x = BatchNormalization(trainable=False)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dense(256)(x)\n",
    "    #x = BatchNormalization(trainable=False)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dense(512)(x)\n",
    "    #x = BatchNormalization(trainable=False)(x)\n",
    "    x = Dense(dim)(x)\n",
    "    x = Reshape((dim,1))(x)\n",
    "elif network_type=='LSTM':\n",
    "# slow training\n",
    "    x = LSTM(256, return_sequences=True)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = LSTM(latent_dim,  return_sequences=False, name='bottleneck')(x)\n",
    "    x = RepeatVector(dim)(x)\n",
    "    x = LSTM(latent_dim, return_sequences=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = LSTM(256, return_sequences=True)(x)\n",
    "    x = TimeDistributed(Dense(1))(x)\n",
    "elif network_type=='CNN':\n",
    "# better than fully connected, but more choices to make for architecture, performance might be very much dependent on architecture\n",
    "    x = Conv1D(filters=64,kernel_size=(5), strides=2, name='conv1', padding='same')(input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPooling1D(2, name='maxpool1', padding='same')(x)\n",
    "    x = Conv1D(filters=32,kernel_size=(3), strides=2,name='conv2', padding='same')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPooling1D(2,name='maxpool2', padding='same')(x)\n",
    "    x = Conv1D(filters=32,kernel_size=(3), strides=2, name='conv3', padding='same')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Flatten()(x)\n",
    "    #x = tf.concat([y,input_params],axis=1)\n",
    "    x = Dense(latent_dim, name='fc_enc')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    #x = tf.concat([z,input_params], axis=1)\n",
    "    x = Dense(1024,name='fc_dec')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((32,32))(x)\n",
    "    x = Conv1DTranspose(input_tensor=x,filters=32,kernel_size=(3),strides=2, name='conv1T', padding='same')\n",
    "    x = BatchNormalization(name='bn1T')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    #x = UpSampling1D(2, name='up1')(x)\n",
    "    x = Conv1DTranspose(input_tensor=x,filters=32,kernel_size=(3),strides=2, name='conv2T', padding='same')\n",
    "    x = BatchNormalization(name='bn2T')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = UpSampling1D(2,name='up2')(x)\n",
    "    x = Conv1DTranspose(input_tensor=x,filters=64,kernel_size=(5),strides=2, name='conv3T', padding='same')\n",
    "    x = BatchNormalization(name='bn3T')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv1DTranspose(input_tensor=x,filters=1,kernel_size=(1),strides=1, padding='same')\n",
    "else:\n",
    "    raise ValueError('Network type not supported')\n",
    "\n",
    "def lossFunction(y_true,y_pred,mask,inverse):\n",
    "        loss = tf.math.square(y_true-y_pred)*inverse\n",
    "        loss = tf.reduce_mean(tf.boolean_mask(loss,mask))\n",
    "        return loss\n",
    "    \n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def compile(self, optimizer, my_loss,metrics, run_eagerly):\n",
    "        super().compile(optimizer,metrics, run_eagerly)\n",
    "        self.my_loss = my_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data = data_adapter.expand_1d(data)\n",
    "        input_data = data_adapter.unpack_x_y_sample_weight(data)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(input_data[0][0], training=True)\n",
    "            loss_value = self.my_loss(input_data[0][0],y_pred,input_data[0][1],input_data[0][2])\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        return {\"training_loss\": loss_value}\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 1000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1000)         0           input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 512)          512512      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 256)          131328      dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 256)          0           dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 64)           16448       leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64)           256         dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 64)           0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 16)           1040        leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 16)           0           dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 8)            136         leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 16)           144         dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16)           64          dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 16)           0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 64)           1088        leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 64)           0           dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 256)          16640       leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 256)          0           dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 512)          131584      leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 1000)         513000      dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 1000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 1000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1000, 1)      0           dense_59[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,324,240\n",
      "Trainable params: 1,323,920\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "lstm_ae = CustomModel(inputs=[input,input_mask,input_noise, input_params], outputs=x)\n",
    "lstm_ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), my_loss=lossFunction, metrics=[],run_eagerly=False)\n",
    "\n",
    "# lstm_ae = Model(inputs=[input, input1,input2, input_float], outputs=[x, input1,input2, input_float])\n",
    "# lstm_ae.compile(optimizer='adam', loss=lossFunction)\n",
    "print(lstm_ae.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scheduler(length, initial_lr,factor=1.2):\n",
    "    \n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch < length:\n",
    "            lr = initial_lr\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-factor)\n",
    "        \n",
    "    return scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_SIZE = len(res_fluxes)\n",
    "train_size   = int(0.7* DATASET_SIZE)\n",
    "test_size    = int(0.1 * DATASET_SIZE)\n",
    "valid_size   = int(0.2 * DATASET_SIZE)\n",
    "indices      = np.arange(DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshuffle(list_, indices):\n",
    "    res = []\n",
    "    for item_ in list_:\n",
    "        res.append(item_[indices])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_fluxes, res_masks, res_inv_vars, redshifts, SNs, ras, decs, category, sublabel = reshuffle([res_fluxes, res_masks, res_inv_vars, redshifts, SNs, ras, decs, category, sublabel], indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new datasize:  218411\n"
     ]
    }
   ],
   "source": [
    "def redshift_bin(min_z, max_z, z_array, arrays):\n",
    "    num  = len(arrays)\n",
    "    z_array = np.asarray(z_array, dtype=np.float32)\n",
    "    indx = np.where((z_array>min_z)*(z_array<max_z))[0]\n",
    "    arrays_new = [arrays[ii][indx] for ii in range(num)]\n",
    "    print('new datasize: ', len(indx))\n",
    "    return arrays_new\n",
    "\n",
    "res_fluxes, res_masks, res_inv_vars, redshifts, SNs, ras, decs, category, sublabel = redshift_bin(.1, .4, redshifts, [res_fluxes, res_masks, res_inv_vars, redshifts, SNs, ras, decs, category, sublabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225126.89487667015\n"
     ]
    }
   ],
   "source": [
    "mean=np.mean(res_fluxes)\n",
    "std = mean=np.std(res_fluxes)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data   = np.expand_dims((res_fluxes[:train_size]-mean)/std,-1)\n",
    "valid_data   = np.expand_dims((res_fluxes[train_size:train_size+valid_size]-mean)/std,-1)\n",
    "test_data    = np.expand_dims((res_fluxes[-test_size::]-mean)/std,-1)\n",
    "\n",
    "train_mask   = np.expand_dims(res_masks[:train_size],-1)\n",
    "valid_mask   = np.expand_dims(res_masks[train_size:train_size+valid_size],-1)\n",
    "test_mask    = np.expand_dims(res_masks[-test_size::],-1)\n",
    "\n",
    "train_noise  = np.expand_dims(res_inv_vars[:train_size],-1)*std**2\n",
    "valid_noise  = np.expand_dims(res_inv_vars[train_size:train_size+valid_size],-1)*std**2\n",
    "test_noise   = np.expand_dims(res_inv_vars[-test_size::],-1)*std**2\n",
    "\n",
    "train_params = np.asarray(redshifts, dtype=np.float32)[:train_size]\n",
    "valid_params = np.asarray(redshifts, dtype=np.float32)[train_size:train_size+valid_size]\n",
    "test_params = np.asarray(redshifts, dtype=np.float32)[-test_size::]\n",
    "\n",
    "train_ras = np.asarray(ras, dtype=np.float32)[:train_size]\n",
    "valid_ras = np.asarray(ras, dtype=np.float32)[train_size:train_size+valid_size]\n",
    "test_ras = np.asarray(ras, dtype=np.float32)[-test_size::]\n",
    "\n",
    "train_decs = np.asarray(decs, dtype=np.float32)[:train_size]\n",
    "valid_decs = np.asarray(decs, dtype=np.float32)[train_size:train_size+valid_size]\n",
    "test_decs = np.asarray(decs, dtype=np.float32)[-test_size::]\n",
    "\n",
    "train_cat = category[:train_size]\n",
    "valid_cat = category[train_size:train_size+valid_size]\n",
    "test_cat = category[-test_size::]\n",
    "\n",
    "train_labels = sublabel[:train_size]\n",
    "valid_labels = sublabel[train_size:train_size+valid_size]\n",
    "test_labels = sublabel[-test_size::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164965"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBC_DUoQDfc4",
    "outputId": "71223b29-ac86-44df-c137-4b787686051b"
   },
   "outputs": [],
   "source": [
    "def training_cycle(BATCH_SIZE, n_epochs, lr_anneal, lr_initial, reduce_fac): \n",
    "    scheduler = make_scheduler(lr_anneal, lr_initial, reduce_fac)\n",
    "    callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    history = lstm_ae.fit(x=(train_data,train_mask,train_noise, train_params), batch_size=BATCH_SIZE, epochs=n_epochs, callbacks=[callback])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    loss = (y_true[0]-y_pred)**2*y_true[2]\n",
    "    valid_loss = np.mean(loss[np.where(y_true[1])])\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 23.8996 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 33.8941 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 116.7949 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 670.7273 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 9.6465 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 13.9147 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 13.2227 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "5156/5156 [==============================] - 11s 2ms/step - training_loss: 9.0140 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "5156/5156 [==============================] - 11s 2ms/step - training_loss: 8.4416 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "5156/5156 [==============================] - 11s 2ms/step - training_loss: 12.1658 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "5156/5156 [==============================] - 11s 2ms/step - training_loss: 11.9522 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "5156/5156 [==============================] - 11s 2ms/step - training_loss: 6.4166 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "5156/5156 [==============================] - 11s 2ms/step - training_loss: 5.5573 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 15.8168 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 4.1406 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 2.3599 - lr: 3.6788e-04\n",
      "Epoch 17/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 1.8170 - lr: 1.3534e-04\n",
      "Epoch 18/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 1.6033 - lr: 4.9787e-05\n",
      "Epoch 19/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 1.5339 - lr: 1.8316e-05\n",
      "Epoch 20/20\n",
      "5156/5156 [==============================] - 10s 2ms/step - training_loss: 1.5108 - lr: 6.7379e-06\n",
      "1.5836767311956732\n",
      "1.4992683801197264\n",
      "Epoch 1/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 5.1624 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.6169 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.3440 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.1614 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.7530 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.2897 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 4.6223 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 3.1485 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.1591 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.1087 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.1555 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.0084 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 2.0628 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 1.8369 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 1.8813 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 1.5366 - lr: 3.6788e-04\n",
      "Epoch 17/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 1.4179 - lr: 1.3534e-04\n",
      "Epoch 18/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 1.3585 - lr: 4.9787e-05\n",
      "Epoch 19/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 1.3308 - lr: 1.8316e-05\n",
      "Epoch 20/20\n",
      "2578/2578 [==============================] - 6s 2ms/step - training_loss: 1.3217 - lr: 6.7379e-06\n",
      "1.3909865633818292\n",
      "1.3166823056474437\n",
      "Epoch 1/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 2.2556 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.4962 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.4598 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.4289 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.4498 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.4159 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.4162 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.4366 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.3045 - lr: 3.6788e-04\n",
      "Epoch 10/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.2684 - lr: 1.3534e-04\n",
      "Epoch 11/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.2590 - lr: 4.9787e-05\n",
      "Epoch 12/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.2551 - lr: 1.8316e-05\n",
      "Epoch 13/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.2532 - lr: 6.7379e-06\n",
      "Epoch 14/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.2522 - lr: 2.4788e-06\n",
      "Epoch 15/15\n",
      "645/645 [==============================] - 2s 3ms/step - training_loss: 1.2521 - lr: 9.1188e-07\n",
      "1.3249138074626747\n",
      "1.250868723247513\n"
     ]
    }
   ],
   "source": [
    "histories =[]\n",
    "for batchsize, nepochs, lr_ann in zip([32,64,256],[20,20,15],[15,15,8]):\n",
    "    histories.append(training_cycle(batchsize, nepochs, lr_ann, 1e-3, 1.))\n",
    "    res_valid = lstm_ae.predict((valid_data,valid_mask,valid_noise, valid_params))\n",
    "    print(custom_metric((valid_data,valid_mask,valid_noise, valid_params),res_valid))\n",
    "    res_train = lstm_ae.predict((train_data[:len(valid_data)],train_mask[:len(valid_data)],train_noise[:len(valid_data)], train_params[:len(valid_data)]))\n",
    "    print(custom_metric((train_data[:len(valid_data)],train_mask[:len(valid_data)],train_noise[:len(valid_data)], train_params[:len(valid_data)]),res_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_valid = lstm_ae.predict((valid_data,valid_mask,valid_noise, valid_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3249138074626747"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_metric((valid_data,valid_mask,valid_noise, valid_params),res_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.append(histories[0].history['training_loss'],histories[1].history['training_loss']))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "dsuE0P7RSsGN"
   },
   "outputs": [],
   "source": [
    "def extract_layers(main_model, starting_layer_ix, ending_layer_ix):\n",
    "    new_model = Sequential()\n",
    "    for ix in range(starting_layer_ix, ending_layer_ix):\n",
    "        curr_layer = main_model.get_layer(index=ix)\n",
    "        print(curr_layer)\n",
    "        new_model.add(curr_layer)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Flatten object at 0x2aabfbdd37f0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfbdd3e20>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfbdcc6a0>\n",
      "<tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x2aabfbdcca30>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfbdccb50>\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x2aabfbdffdf0>\n",
      "<tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x2aabfba46400>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfbdf3d00>\n",
      "<tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x2aabfba75e20>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfba75df0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfba6ee80>\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x2aabfba7deb0>\n",
      "<tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x2aabfbe2e520>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfba55a90>\n",
      "<tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x2aabfbe057c0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfbe05850>\n",
      "<tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x2aabfbe0d970>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfbe0dca0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2aabfbe19280>\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2aace35c8100>\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2aabfbdd34c0>\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2aace35c8df0>\n"
     ]
    }
   ],
   "source": [
    "encoder = extract_layers(lstm_ae,1,11)\n",
    "\n",
    "decoder = extract_layers(lstm_ae,11,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.build((None,fixed_num_bins))\n",
    "decoder.build((None,latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 661,720\n",
      "Trainable params: 661,464\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1000)              513000    \n",
      "_________________________________________________________________\n",
      "input_23 (InputLayer)        [(None, 1000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "input_24 (InputLayer)        [(None, 1000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "input_22 (InputLayer)        [(None, 1)]               0         \n",
      "=================================================================\n",
      "Total params: 662,520\n",
      "Trainable params: 662,456\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_valid = encoder.predict(valid_data)\n",
    "encoded_train = encoder.predict(train_data)\n",
    "encoded_test = encoder.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_valid = decoder.predict(encoded_valid)\n",
    "decoded_train = decoder.predict(encoded_train)\n",
    "decoded_test = decoder.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/cscratch1/sd/vboehm/Models/SDSS_AE/encoder_galaxies_quasars_bins1000_wl3388-8318_minz01_maxz036_minSN50_8_fully_connected_xlarge_std_one_batch/assets\n",
      "INFO:tensorflow:Assets written to: /global/cscratch1/sd/vboehm/Models/SDSS_AE/decoder_galaxies_quasars_bins1000_wl3388-8318_minz01_maxz036_minSN50_8_fully_connected_xlarge_std_one_batch/assets\n",
      "/global/cscratch1/sd/vboehm/Models/SDSS_AE/decoder_galaxies_quasars_bins1000_wl3388-8318_minz01_maxz036_minSN50_8_fully_connected_xlarge_std_one_batch\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(root_models,'encoder_%s'%label_2)\n",
    "encoder.save(path)\n",
    "path = os.path.join(root_models,'decoder_%s'%label_2)\n",
    "decoder.save(path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(root_models,'encoder_%s'%label_2)\n",
    "encoder = tf.keras.models.load_model(path)\n",
    "path = os.path.join(root_models,'decoder_%s'%label_2)\n",
    "decoder = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(root_encoded,'encoded_%s.npy'%label_2),[encoded_train, encoded_valid, encoded_test])\n",
    "encoded_train, encoded_valid, encoded_test = np.load(os.path.join(root_encoded,'encoded_%s.npy'%label_2), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(root_decoded,'decoded_%s.npy'%label_2),[decoded_train,decoded_valid, decoded_test])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVpklEQVR4nO3dcbBmdX3f8fcnewNpNKLiTcYAyV0LZLpOHKPX1UwjbbKJLrZhY7PExUxFSoc4ZqfdsWmzjJQQ4gwhjWHbCdNICyliLJJtne6UtatZqZ3JKN0LIrgieKFErkv0GqiWWsWVb/94ziUPD8/de+69z73P3cP7NfPMnvM7v/Oc7z3Ps5/n3POc87upKiRJ3fV94y5AkrS2DHpJ6jiDXpI6zqCXpI4z6CWp4ybGXcCgl73sZTU1NTXuMiTppHLXXXd9vaomhy3bcEE/NTXFzMzMuMuQpJNKkr9YbJmnbiSp4wx6Seo4g16SOq5V0CfZnuSBJLNJ9g5Zfl6Su5McT7JzyPIXJflKkj8cRdGSpPaWDPokm4DrgfOBLcBFSbYMdPsy8E7gw4s8ze8An1p5mZKklWpzRL8VmK2qh6vqKeBWYEd/h6p6pKruBZ4eXDnJa4EfAT4+gnolScvUJujPAB7tm59r2paU5PuA9wP/fPmlSZJGoU3QZ0hb27GN3w0crKpHT9QpyWVJZpLMzM/Pt3xqSVIbbW6YmgPO6ps/EzjW8vl/GnhjkncDLwROSfJkVT3rC92qugG4AWB6etoB8iVphNoE/RHgnCSbga8Au4C3t3nyqvrVhekk7wSmB0NekrS2ljx1U1XHgd3AIeB+4LaqOprk6iQXACR5XZI54ELgA0mOrmXRkqT2stH+lOD09HQ51o0kLU+Su6pqetgy74yVpI4z6CWp4wx6Seo4g16SOs6gl6SOM+glqeMMeknqOINekjrOoJdamtp7+7hLkFbEoJekjjPopZb2TOwfdwnSihj0ktRxBr0kdZxBL0kdZ9BLUscZ9JLUcQa9JHWcQS9JHWfQS1LHGfSS1HEGvSR1XKugT7I9yQNJZpPsHbL8vCR3JzmeZGdf+6uTfDrJ0ST3JnnbKIuXJC1tyaBPsgm4Hjgf2AJclGTLQLcvA+8EPjzQ/i3gHVX1SmA7sC/Ji1dbtCSpvYkWfbYCs1X1MECSW4EdwBcWOlTVI82yp/tXrKoH+6aPJfkaMAn871VXLklqpc2pmzOAR/vm55q2ZUmyFTgFeGjIssuSzCSZmZ+fX+5TS5JOoE3QZ0hbLWcjSV4O3AJcUlVPDy6vqhuqarqqpicnJ5fz1JKkJbQJ+jngrL75M4FjbTeQ5EXA7cAVVfWZ5ZUnSVqtNkF/BDgnyeYkpwC7gANtnrzp/1Hgg1X1pysvU5K0UksGfVUdB3YDh4D7gduq6miSq5NcAJDkdUnmgAuBDyQ52qz+K8B5wDuT3NM8Xr0mP4kkaag2V91QVQeBgwNtV/ZNH6F3SmdwvQ8BH1pljZKkVfDOWEnqOINekjrOoJekjjPoJanjDHpJ6jiDXpI6zqCXpI4z6CWp4wx6Seo4g16SOs6gl6SOM+glqeMMeknqOINekjrOoJekjjPoJanjDHpJ6jiDXpI6zqCXpI4z6CWp4wx6Seq4VkGfZHuSB5LMJtk7ZPl5Se5OcjzJzoFlFyf5UvO4eFSFS5LaWTLok2wCrgfOB7YAFyXZMtDty8A7gQ8PrPtS4LeA1wNbgd9K8pLVly1JaqvNEf1WYLaqHq6qp4BbgR39Harqkaq6F3h6YN03A5+oqser6gngE8D2EdQtSWqpTdCfATzaNz/XtLXRat0klyWZSTIzPz/f8qklSW20CfoMaauWz99q3aq6oaqmq2p6cnKy5VNL6+iOa8ZdgbRibYJ+Djirb/5M4FjL51/NutKGse/wg+MuQVqxNkF/BDgnyeYkpwC7gAMtn/8Q8KYkL2m+hH1T0yZJWidLBn1VHQd20wvo+4HbqupokquTXACQ5HVJ5oALgQ8kOdqs+zjwO/Q+LI4AVzdtkqR1MtGmU1UdBA4OtF3ZN32E3mmZYeveBNy0iholSavgnbGS1HEGvSR1nEEvSR1n0EvLMLX39nGXIC2bQS8tw56J/eMuQVo2g16SOs6gl6SOM+glqeMMeknqOINekjrOoJekjjPoJanjDHpJ6jiDXpI6zqCXpI4z6CWp4wx6Seo4g16SOs6gl6SOM+glqeMMeknquFZBn2R7kgeSzCbZO2T5qUk+0iy/M8lU0/79SW5Ocl+S+5NcPtryJUlLWTLok2wCrgfOB7YAFyXZMtDtUuCJqjobuA64tmm/EDi1qn4SeC3wawsfApKk9dHmiH4rMFtVD1fVU8CtwI6BPjuAm5vp/cC2JAEKeEGSCeBvAE8B3xxJ5ZKkVtoE/RnAo33zc03b0D5VdRz4BnA6vdD/v8BjwJeB36+qxwc3kOSyJDNJZubn55f9Q0iSFtcm6DOkrVr22Qp8D/hRYDPwz5K84jkdq26oqumqmp6cnGxRkiSprTZBPwec1Td/JnBssT7NaZrTgMeBtwP/raq+W1VfA/4cmF5t0ZKk9toE/RHgnCSbk5wC7AIODPQ5AFzcTO8EPllVRe90zc+l5wXAG4AvjqZ0SVIbSwZ9c859N3AIuB+4raqOJrk6yQVNtxuB05PMAu8BFi7BvB54IfB5eh8Yf1xV9474Z5AkncBEm05VdRA4ONB2Zd/0t+ldSjm43pPD2iVJ68c7YyWp4wx6Seo4g16SOs6gl5ZyxzXjrkBaFYNeWsK+ww+OuwRpVQx6Seo4g16SOs6gl6SOM+glqeMMeknqOINekjrOoJekjjPoJanjDHpJ6jiDXpI6zqCXpI4z6CWp4wx6Seo4g16SOs6gl6SOM+glqeNaBX2S7UkeSDKbZO+Q5acm+Uiz/M4kU33LXpXk00mOJrkvyQ+MrnxJ0lKWDPokm4DrgfOBLcBFSbYMdLsUeKKqzgauA65t1p0APgS8q6peCfxd4Lsjq16StKQ2R/RbgdmqeriqngJuBXYM9NkB3NxM7we2JQnwJuDeqvocQFX9VVV9bzSlS5LaaBP0ZwCP9s3PNW1D+1TVceAbwOnAuUAlOZTk7iT/YtgGklyWZCbJzPz8/HJ/BknSCbQJ+gxpq5Z9JoCfAX61+fetSbY9p2PVDVU1XVXTk5OTLUqSJLXVJujngLP65s8Eji3WpzkvfxrweNP+qar6elV9CzgIvGa1RUuS2msT9EeAc5JsTnIKsAs4MNDnAHBxM70T+GRVFXAIeFWSH2w+AP4O8IXRlC5JamNiqQ5VdTzJbnqhvQm4qaqOJrkamKmqA8CNwC1JZukdye9q1n0iyR/Q+7Ao4GBV3b5GP4skaYglgx6gqg7SO+3S33Zl3/S3gQsXWfdD9C6xlE46U3tvZ0+r/yXSxuWdsdIJ7JnYP+4SpFUz6CWp4wx6Seo4g15arjuuGXcF0rIY9JLUcQa9JHWcQS8t077DD467BGlZDHpJ6jiDXlrE1F5v4lY3GPTSIrxZSl1h0EtSxxn0ktRxBr0kdZxBLw3hF7HqEoNeGsIvYtUlBr0kdZxBL0kdZ9BLUscZ9JLUcQa9NMArbtQ1Br0kdVyroE+yPckDSWaT7B2y/NQkH2mW35lkamD5jyV5MslvjKZsae14aaW6ZsmgT7IJuB44H9gCXJRky0C3S4Enqups4Drg2oHl1wEfW325kqTlanNEvxWYraqHq+op4FZgx0CfHcDNzfR+YFuSACT5JeBh4OhoSpYkLUeboD8DeLRvfq5pG9qnqo4D3wBOT/IC4DeB3z7RBpJclmQmycz8/Hzb2iVJLbQJ+gxpq5Z9fhu4rqqePNEGquqGqpququnJyckWJUmS2ppo0WcOOKtv/kzg2CJ95pJMAKcBjwOvB3Ym+T3gxcDTSb5dVX+46solSa20CfojwDlJNgNfAXYBbx/ocwC4GPg0sBP4ZFUV8MaFDkmuAp405CVpfS0Z9FV1PMlu4BCwCbipqo4muRqYqaoDwI3ALUlm6R3J71rLoiVJ7bU5oqeqDgIHB9qu7Jv+NnDhEs9x1QrqkyStknfGSlLHGfSS1HEGvSR1nEEvSR1n0EtSxxn00go4Zr1OJga9tAIOZayTiUEvSR1n0EtSxxn0ktRxBr3U745rxl2BNHIGvdRn3+EHx12CNHIGvSR1nEEvSR1n0EtSxxn0ktRxBr0kdZxBL0kdZ9BLK+TAZjpZGPTSCjmwmU4WBr0kdVyroE+yPckDSWaT7B2y/NQkH2mW35lkqmn/hSR3Jbmv+ffnRlu+JGkpSwZ9kk3A9cD5wBbgoiRbBrpdCjxRVWcD1wHXNu1fB36xqn4SuBi4ZVSFS5LaaXNEvxWYraqHq+op4FZgx0CfHcDNzfR+YFuSVNVnq+pY034U+IEkp46icGlDcBA0nQTaBP0ZwKN983NN29A+VXUc+AZw+kCfXwY+W1XfGdxAksuSzCSZmZ+fb1u7JKmFNkGfIW21nD5JXknvdM6vDdtAVd1QVdNVNT05OdmiJGljcLRLnQzaBP0ccFbf/JnAscX6JJkATgMeb+bPBD4KvKOqHlptwdKG4+kbbXBtgv4IcE6SzUlOAXYBBwb6HKD3ZSvATuCTVVVJXgzcDlxeVX8+qqKljcSjem10SwZ9c859N3AIuB+4raqOJrk6yQVNtxuB05PMAu8BFi7B3A2cDfzLJPc0jx8e+U8hjcC+Ky4ZdwnSmpho06mqDgIHB9qu7Jv+NnDhkPXeB7xvlTVKklbBO2MlqeMMeknqOINeAq+cUacZ9HpeWxhq2Ctn1GUGvZ63nhlPfhRH8/5GoA2s1VU3Upfsu+IS9mw7lz0TvaP4fYdH8JyHH2TPzy5vnYUPmkd+9++tvgDpBAx6ddrU3tt55M33PufUzLhP1ey74hL2TCxM72ff8Z0GvtaMp27UOVN7b+/d/HTHNeyZ2L9uob6aG672TOz39I/WjEGvzln4E3/jOGpf+IBZ0bqHH3xmfe/S1Sh56kadsVHCcd/hB9nDNfCzlz9n2dTe25f8W7PjPq2k7jHoddLbKAHfb9/hB+Hws+vad3ynf1BcY+GpG53UNmLIL8aQ17h4RK+TzskU7qux74pL2PO+Px53GeoAj+h1Unm+hLw0Sh7Ra0Nb7Dp4Se15RK+NZ+HywnW+Dn5D8tp6jYBH9BqLqb23//WdoHdcMzTMn9cB31jJ0ArSoFTVuGt4lunp6ZqZmRl3GVpDnmdfmT3bzmXq0KuemXfIBPVLcldVTQ9dZtBrLTwzYJfn19ecV+YIDHqtg4VTMR6tj48Doz2/GfQamWfOrS9yXl0bi0f7zx+rDvok24F/DWwC/n1V/e7A8lOBDwKvBf4KeFtVPdIsuxy4FPge8E+q6tCJtmXQj19/mC8w1E9+e7adO3T8HXXDqoI+ySbgQeAXgDngCHBRVX2hr8+7gVdV1buS7ALeWlVvS7IF+I/AVuBHgT8Dzq2q7y22PYN+7XlUrn4e9XfDaoP+p4GrqurNzfzlAFV1TV+fQ02fTyeZAP4SmAT29vft77fY9p5vQf+sywwB7riGqUOv+uuhdo/vPOEXmnu2nWtYaywWfkN4zntYY7HaoN8JbK+qf9zM/0Pg9VW1u6/P55s+c838Q8DrgauAz1TVh5r2G4GPVdX+gW1cBlzWzP4E8MByf8g+LwO+vor114p1LY91LY91LU8X6/rxqpoctqDNDVMZ0jb46bBYnzbrUlU3ADe0qGVJSWYW+1QbJ+taHutaHutanudbXW2GQJgDzuqbPxM4tlif5tTNacDjLdeVJK2hNkF/BDgnyeYkpwC7gAMDfQ4AFzfTO4FPVu+c0AFgV5JTk2wGzgH+52hKlyS1seSpm6o6nmQ3cIje5ZU3VdXRJFcDM1V1ALgRuCXJLL0j+V3NukeT3AZ8ATgO/PqJrrgZkZGcAloD1rU81rU81rU8z6u6NtwNU5Kk0XKYYknqOINekjrupA36JBcmOZrk6STTA8suTzKb5IEkb+5r3960zSbZuw41fiTJPc3jkST3NO1TSf5f37I/WutaBuq6KslX+rb/lr5lQ/fdOtX1r5J8Mcm9ST6a5MVN+1j3V1PDur53TlDHWUnuSHJ/8/7/p037oq/pOtb2SJL7mu3PNG0vTfKJJF9q/n3JOtf0E3375J4k30yyZ1z7K8lNSb7W3Hu00DZ0H6Xn3zTvuXuTvGbFG66qk/IB/C16N1f9d2C6r30L8DngVGAz8BC9L5E3NdOvAE5p+mxZx3rfD1zZTE8Bnx/jvrsK+I0h7UP33TrW9SZgopm+Frh2g+yvsb53Bmp5OfCaZvqH6A1PsmWx13Sda3sEeNlA2+8Be5vpvQuv6Rhfx78Efnxc+ws4D3hN//t5sX0EvAX4GL37kd4A3LnS7Z60R/RVdX9VDbuDdgdwa1V9p6r+FzBLb6ydrcBsVT1cVU8BtzZ911ySAL9Cb9yfjWyxfbcuqurjVXW8mf0MvfsuNoKxvXcGVdVjVXV3M/1/gPuBM8ZRS0s7gJub6ZuBXxpjLduAh6rqL8ZVQFX9D3pXJvZbbB/tAD5YPZ8BXpzk5SvZ7kkb9CdwBvBo3/xc07ZY+3p4I/DVqvpSX9vmJJ9N8qkkb1ynOvrtbn4dvKnv1+lx7qNB/4je0cyCce6vjbRfnpFkCvgp4M6madhrup4K+HiSu9Ib1gTgR6rqMeh9SAE/PIa6Fuzi2Qdb495fCxbbRyN7323ooE/yZ0k+P+RxoqOpVQ3HsEY1XsSz32CPAT9WVT8FvAf4cJIXrbaWZdT1b4G/Cby6qeX9C6sNeaqRXn/bZn8leS+9+y7+pGla8/21VNlD2sZ6XXKSFwL/CdhTVd9k8dd0Pf3tqnoNcD7w60nOG0MNQ6V3s+cFwJ82TRthfy1lZO+7Df3Hwavq51ew2omGXRj5cAxL1ZjekBD/gN5Y/QvrfAf4TjN9V3qDwJ0LjGzYzrb7Lsm/A/5rM7vmQ1a02F8XA38f2FbNicr12F9L2FBDeST5fnoh/ydV9Z8Bquqrfcv7X9N1U1XHmn+/luSj9E55fTXJy6vqsea0w9fWu67G+cDdC/tpI+yvPovto5G97zb0Ef0KLTbsQpuhHNbCzwNfrGZkT4Akk+mN80+SVzQ1PrwOtSxsv/8831uBhSsAxjpkRXp/4OY3gQuq6lt97WPdX4zvvfMczfc9NwL3V9Uf9LUv9pquV10vSPJDC9P0vlj/PM8eHuVi4L+sZ119nvVb9bj314DF9tEB4B3N1TdvAL6xcIpn2cbx7feIvr1+K71PvO8AXwUO9S17L72rJB4Azu9rfwu9qxQeAt67TnX+B+BdA22/DByld/XG3cAvrvO+uwW4D7i3eTO9fKl9t051zdI7J3lP8/ijjbC/xvXeWaSOn6H36/u9ffvpLSd6Tdeprlc0r8/nmtfqvU376cBh4EvNvy8dwz77QXp/+e60vrax7C96HzaPAd9t8uvSxfYRvVM31zfvufvou7pwuQ+HQJCkjuviqRtJUh+DXpI6zqCXpI4z6CWp4wx6Seo4g16SOs6gl6SO+/+g+hIwv5Pr4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(encoded_valid.flatten(),bins=1000,density=True, range=(-100,100))\n",
    "_=plt.hist(encoded_train.flatten(),bins=1000,density=True, alpha=0.5, range=(-100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47133"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,4, figsize=(20,4))\n",
    "ax=ax.flatten()\n",
    "for ii in range(latent_dim):\n",
    "    jj= (ii+1)%latent_dim\n",
    "    im = ax[ii].scatter(encoded_valid[:,ii],encoded_valid[:,jj],c=valid_params, cmap='nipy_spectral',s=1)\n",
    "    plt.colorbar(im, ax=ax[ii])\n",
    "    ax[ii].set_xlim(-100,100)\n",
    "    ax[ii].set_ylim(-100,100)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(2,4, figsize=(20,4))\n",
    "ax=ax.flatten()\n",
    "for ii in range(latent_dim):\n",
    "    jj= (ii+1)%latent_dim\n",
    "    im = ax[ii].scatter(encoded_train[:47000,ii],encoded_train[:47000,jj],c=train_params[:47000], cmap='nipy_spectral',s=1)\n",
    "    plt.colorbar(im, ax=ax[ii])\n",
    "    ax[ii].set_xlim(-100,100)\n",
    "    ax[ii].set_ylim(-100,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(sublabel)\n",
    "print(le.classes_, le.transform(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,4, figsize=(20,4))\n",
    "ax=ax.flatten()\n",
    "for ii in range(latent_dim):\n",
    "    jj= (ii+1)%latent_dim\n",
    "    im = ax[ii].scatter(encoded_valid[:,ii],encoded_valid[:,jj],c=le.transform(valid_labels), cmap='Set1', s=1)\n",
    "    plt.colorbar(im, ax=ax[ii])\n",
    "    ax[ii].set_xlim(-100,100)\n",
    "    ax[ii].set_ylim(-100,100)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(2,4, figsize=(20,4))\n",
    "ax=ax.flatten()\n",
    "for ii in range(latent_dim):\n",
    "    jj= (ii+1)%latent_dim\n",
    "    im = ax[ii].scatter(encoded_train[:47000,ii],encoded_train[:47000,jj],c=le.transform(train_labels)[:47000], cmap='Set1', s=1)\n",
    "    plt.colorbar(im, ax=ax[ii])\n",
    "    ax[ii].set_xlim(-100,100)\n",
    "    ax[ii].set_ylim(-100,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_list=['dark_background']\n",
    "# Plot a demonstration figure for every available style sheet.\n",
    "for style_label in style_list:\n",
    "    with plt.rc_context({\"figure.max_open_warning\": len(style_list)}):\n",
    "        with plt.style.context(style_label):\n",
    "            fig, ax = plt.subplots(5,5, figsize=(25,15))\n",
    "            ax = ax.flatten()\n",
    "            for nn, ii in enumerate(np.arange(25)):\n",
    "                ax[nn].plot(new_wl[:-1], (np.squeeze(valid_data*std)[ii]+mean)*np.squeeze(valid_mask)[ii], )\n",
    "                ax[nn].plot(new_wl[:-1], (np.squeeze(decoded_valid*std)[ii]+mean)*np.squeeze(valid_mask)[ii], color='orange')\n",
    "                ax[nn].plot(new_wl[:-1], (np.squeeze(decoded_valid*std)[ii]+mean), color='red')\n",
    "                ax[nn].text(0.05, 0.92, r'z=%.2f'%valid_params[ii], fontsize=15, color='white',verticalalignment='top', horizontalalignment='left', transform=ax[nn].transAxes)\n",
    "                ax[nn].text(0.05, 0.82, r'label=%s,%s'%(valid_labels[ii],valid_cat[ii]), fontsize=15, color='white',verticalalignment='top', horizontalalignment='left', transform=ax[nn].transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens=[]\n",
    "for ii in range(latent_dim):\n",
    "    res = np.mean(enc,axis=0)\n",
    "    res[ii]+=1\n",
    "    sens+=[res]\n",
    "for ii in range(latent_dim):\n",
    "    res = np.mean(enc,axis=0)\n",
    "    res[ii]-=1\n",
    "    sens+=[res]\n",
    "sens+=[np.mean(enc,axis=0)]\n",
    "sens = np.asarray(sens)\n",
    "test = decoder.predict(sens)\n",
    "\n",
    "for ii in range(8):\n",
    "    plt.plot(test[ii]-test[8+ii])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbeXyhiihZQbSo0juhrHje",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LSTM-AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
