{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/VMBoehm/SDSS_PAE/blob/main/LSTM_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqDqXXTQ1FMN"
   },
   "source": [
    "# Data Preparation Stage 1\n",
    "- restrict all spectra onto same wavelengths interval and rescale to common grid\n",
    "- filter out zwarnings\n",
    "- enforce weak target selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import Planck18_arXiv_v2 as cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZcR4zT3V8dMc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! pip install tensorflow-probability==0.11.0\n",
    "# ! pip install --user -e /global/homes/v/vboehm/codes/SDSS_PAE/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZME24z11ITl"
   },
   "source": [
    "#### load some SDSS data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sdss_pae.sdss_dataset as sdss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('sdss', data_dir='/global/cscratch1/sd/vboehm/Datasets/SDSS_BOSS_good',with_info=True, split='train', download=True)\n",
    "tot_num = info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='sdss',\n",
       "    full_name='sdss/1.0.0',\n",
       "    description=\"\"\"\n",
       "    selected features from spAll and spZbest files \n",
       "    'flux': measured spectrum in  \n",
       "    'inv_var': inverse variance\n",
       "    'and_mask': and mask (set to 1 for all non-zero entries)\n",
       "    'coeffs': c0, c1, npix. calculate wavelengths with `10.**(c0 + c1 * np.arange(npix))`\n",
       "    'label': type of object, 'STAR'==0, 'QSO'==1, 'GALAXY'==2\n",
       "    'redshift': object redshift estimate\n",
       "    \"\"\",\n",
       "    homepage='https://www.sdss.org/science/data-release-publications/',\n",
       "    data_path='/global/cscratch1/sd/vboehm/Datasets/SDSS_BOSS_good/sdss/1.0.0',\n",
       "    download_size=Unknown size,\n",
       "    dataset_size=199.20 GiB,\n",
       "    features=FeaturesDict({\n",
       "        'DEC': tf.float32,\n",
       "        'MJD': tf.int32,\n",
       "        'RA': tf.float32,\n",
       "        'and_mask': Tensor(shape=(None, 1), dtype=tf.int32),\n",
       "        'coeffs': Tensor(shape=(3, 1), dtype=tf.float32),\n",
       "        'fiber': tf.int32,\n",
       "        'filename': Text(shape=(), dtype=tf.string),\n",
       "        'flux': Tensor(shape=(None, 1), dtype=tf.float32),\n",
       "        'folder': Text(shape=(), dtype=tf.string),\n",
       "        'inv_var': Tensor(shape=(None, 1), dtype=tf.float32),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
       "        'plate': tf.int32,\n",
       "        'redshift': tf.float32,\n",
       "        'sublabel': Text(shape=(), dtype=tf.string),\n",
       "        'zwarning': tf.int32,\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'train': <SplitInfo num_examples=5300240, num_shards=1024>,\n",
       "    },\n",
       "    citation=\"\"\"\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mm<5:\n",
    "    ds, info = tfds.load('sdss', data_dir='/global/cscratch1/sd/vboehm/Datasets/SDSS_BOSS_good',with_info=True, split='train[%d:%d]'%(mm*1000000,(mm+1)*1000000), download=True)\n",
    "    num_examples = info.splits['train[%d:%d]'%(mm*1000000,(mm+1)*1000000)].num_examples\n",
    "else:\n",
    "    ds, info = tfds.load('sdss', data_dir='/global/cscratch1/sd/vboehm/Datasets/SDSS_BOSS_good',with_info=True, split='train[%d:%d]'%(mm*1000000,tot_num), download=True)\n",
    "    num_examples = info.splits['train[%d:%d]'%(mm*1000000,tot_num)].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300240\n"
     ]
    }
   ],
   "source": [
    "print(num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### settings\n",
    "root_models     = '/global/cscratch1/sd/vboehm/Models/SDSS_AE/'\n",
    "\n",
    "root_encoded    = '/global/cscratch1/sd/vboehm/Datasets/encoded/sdss/'\n",
    "root_decoded    = '/global/cscratch1/sd/vboehm/Datasets/decoded/sdss/'\n",
    "root_data       = '/global/cscratch1/sd/vboehm/Datasets'\n",
    "\n",
    "root_prepped    = os.path.join(root_data,'sdss/prepped')\n",
    "\n",
    "wlmin, wlmax    = (3388,8318)\n",
    "fixed_num_bins  = 1000\n",
    "select_by       = [1,2] \n",
    "de_redshift     = True\n",
    "label           = 'galaxies_quasars_bins%d_wl%d-%d'%(fixed_num_bins,wlmin,wlmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, MJD_t, plate_t, fiber_t, objid_t = np.load(os.path.join(root_data,'SDSS_BOSS_data/target_selection.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388474"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = [[MJD_t[ii], plate_t[ii], fiber_t[ii]] for ii in range(len(target))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388474"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ref  = 0.1\n",
    "ld_ref = cosmo.luminosity_distance(z_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataset by redshifts and type\n",
    "\n",
    "def filter_type_fn(x):\n",
    "    if select_by is not None:\n",
    "        x = x['label']\n",
    "        s = tf.ones(len(select_by), dtype=tf.int64)*np.asarray(select_by)\n",
    "        tile_multiples = tf.concat([tf.ones(tf.shape(tf.shape(x)), dtype=tf.int32), tf.shape(s)], axis=0)\n",
    "        x_tile = tf.tile(tf.expand_dims(x, -1), tile_multiples)\n",
    "        x_in_s = tf.reduce_any(tf.equal(x_tile, s), -1)\n",
    "        return x_in_s\n",
    "    else: return 1\n",
    "    \n",
    "def filter_zwarning_fn(x):\n",
    "    return tf.math.equal(x['zwarning'], 0)\n",
    "\n",
    "    \n",
    "def filter_redshift_fn(x):\n",
    "    return tf.math.greater(x['redshift'], 0)\n",
    "\n",
    "#ds = ds.filter(filter_type_fn)\n",
    "ds = ds.filter(filter_redshift_fn)\n",
    "ds = ds.filter(filter_zwarning_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a2f7b359b7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDATASET_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'size of subselected data:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf22/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf22/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf22/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;31m# and instead mimic ops placement in graphs: Operations on resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;31m# handles execute on the same device as where the resource is placed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf22/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2350\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2351\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=len(list(ds))\n",
    "print('size of subselected data:', DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(objid_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beEnDqGV9f-9"
   },
   "outputs": [],
   "source": [
    "# computing maximum and minimum redhsift in the data sample, getting distribution of data sizes\n",
    "# this doe not need to be run every time - especially if wavelength range is set by user\n",
    "\n",
    "try:\n",
    "    wl_range = np.load('wl_range_%s.npy'%label)\n",
    "except:\n",
    "    ii          = 0\n",
    "    min_wl      = 100\n",
    "    max_wl      = -100\n",
    "    num_npixs   = []\n",
    "    img_coeffs1 = []\n",
    "    img_coeffs2 = []\n",
    "    factors     = []\n",
    "    min_z       = 5\n",
    "    max_z       = -5\n",
    "    redshifts   = []\n",
    "\n",
    "    for image in tfds.as_numpy(ds):\n",
    "        log10wl = image['coeffs'][0][0] + image['coeffs'][1][0] * np.arange(image['coeffs'][2][0])\n",
    "        if de_redshift:\n",
    "            log10wl = log10wl-np.log10(1+image['redshift'])\n",
    "        if max(log10wl)>max_wl:\n",
    "            max_wl= max(log10wl)\n",
    "        if min(log10wl)<min_wl:\n",
    "            min_wl=min(log10wl)\n",
    "        redshifts.append(image['redshift'])\n",
    "\n",
    "    wl_range = (min_wl, max_wl) \n",
    "\n",
    "    np.save('wl_range_%s.npy'%label,wl_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wl, max_wl = wl_range\n",
    "print(10**min_wl, 10**max_wl)\n",
    "\n",
    "# compute number of pixels that span entire wl range:\n",
    "npix_max = -(min_wl-max_wl)/np.unique(1e-4)\n",
    "print(npix_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_range      = (np.log10(wlmin),np.log10(wlmax))\n",
    "# new binning \n",
    "new_wl        = np.logspace(wl_range[0],wl_range[1],fixed_num_bins+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.diff(new_wl))\n",
    "plt.plot(np.diff(10**(min_wl+np.arange(npix_max)*1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_flux           = []\n",
    "raw_noise          = []\n",
    "raw_masks          = []\n",
    "decs               = []\n",
    "ras                = []\n",
    "sublabel           = []\n",
    "plate_id           = []\n",
    "MJD                = []\n",
    "fiber              = []\n",
    "folder             = []\n",
    "\n",
    "res_fluxes         = []\n",
    "res_inv_vars       = []\n",
    "res_masks          = []\n",
    "redshifts          = []\n",
    "category           = []\n",
    "\n",
    "SNs                = []\n",
    "\n",
    "flag               = []\n",
    "\n",
    "ii=0\n",
    "\n",
    "for nn, image in enumerate(tfds.as_numpy(ds)):\n",
    "    ## this is not a correct selection, but a pre-selection. strict selection is too expensive on full dataset\n",
    "    ## in step 2 we do the full cut\n",
    "    if (image['fiber'] in fiber_t) and (image['MJD'] in MJD_t) and (image['plate'] in plate_t):\n",
    "        if ii%1000==0:\n",
    "            print(ii)\n",
    "        if image['zwarning']>0:\n",
    "            print('bad spectrum')\n",
    "\n",
    "        # compute wavelengths\n",
    "        log10wl  = image['coeffs'][0][0] + image['coeffs'][1][0] * np.arange(image['coeffs'][2][0])\n",
    "        log10wl  = log10wl\n",
    "        wl       = 10**log10wl\n",
    "\n",
    "        raw_flux.append(image['flux'])\n",
    "        raw_noise.append(image['inv_var'])\n",
    "        raw_masks.append(image['and_mask'])\n",
    "\n",
    "        ##rescale flux by wavelength and distance\n",
    "        factor   = (cosmo.luminosity_distance(image['redshift'])/ld_ref)**2\n",
    "        #flux\n",
    "\n",
    "        ### change that to before de-redshifting\n",
    "        flux     = image['flux'][:,0]*factor*wl\n",
    "        #inv_var\n",
    "        inv_var  = image['inv_var'][:,0]/(wl*factor)**2\n",
    "\n",
    "        wl/=(1.+image['redshift'])\n",
    "\n",
    "        ## mask\n",
    "\n",
    "        #mask\n",
    "        mask           = np.squeeze(image['and_mask'])\n",
    "        #mask pixels that are completely noise dominated (mask!)\n",
    "        noise_         = np.squeeze(inv_var)\n",
    "        ind            = np.where(noise_==0.)\n",
    "        mask[ind]      = False \n",
    "\n",
    "        mask_ind = np.where(mask)\n",
    "\n",
    "        if len(mask_ind[0])==0:\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            res_flux, _, _ = binned_statistic(wl[mask_ind], flux[mask_ind],bins=new_wl)\n",
    "\n",
    "\n",
    "\n",
    "            noise          = 1./noise_[mask_ind]\n",
    "            noise_, _, _   = binned_statistic(wl[mask_ind],noise,bins=new_wl)\n",
    "            N, _, _        = binned_statistic(wl[mask_ind],values=np.zeros(len(wl[mask_ind])),statistic='count',bins=new_wl)\n",
    "            new_mask_ind   = np.where(N==0)\n",
    "            noise_         = noise_/N\n",
    "            inv_var_res    = 1./noise_\n",
    "            res_flux[new_mask_ind] = 0\n",
    "            res_fluxes.append(res_flux)\n",
    "\n",
    "            new_mask_cons = np.ones(len(new_wl)-1,dtype=np.int32)\n",
    "            new_mask_cons[new_mask_ind] = 0\n",
    "\n",
    "\n",
    "            res_masks.append(new_mask_cons)\n",
    "\n",
    "\n",
    "            SN = np.sum(res_flux)/np.sqrt(np.sum(1./inv_var_res))\n",
    "            SNs.append(SN)\n",
    "\n",
    "            inv_var_res[new_mask_ind] = 0\n",
    "            res_inv_vars.append(inv_var_res)\n",
    "\n",
    "            redshifts.append(image['redshift'])\n",
    "            ras.append(image['RA'])\n",
    "            decs.append(image['DEC'])\n",
    "            sublabel.append(image['sublabel'])\n",
    "            category.append(image['label'])\n",
    "            MJD.append(image['MJD'])\n",
    "            fiber.append(image['fiber'])\n",
    "            plate_id.append(image['plate'])\n",
    "            folder.append(image['folder'])\n",
    "\n",
    "            ii+=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ii, mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pre-selected data, actual selection is subset\n",
    "np.save(os.path.join(root_data,'SDSS_BOSS_preprocessed/%s_%d_target_selection_QSO_GAL.npy'%(label,mm)), [res_fluxes,res_inv_vars,res_masks,redshifts,SNs, ras, decs, category,sublabel, MJD, plate_id, fiber, folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbeXyhiihZQbSo0juhrHje",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LSTM-AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
