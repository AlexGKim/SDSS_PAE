{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f65200-2db4-4ddb-9069-06f59a58b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1a59e5-b64c-4e4c-a96b-8ff0e6d7d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5d9ec3-a68a-40fa-94c2-01e1e527c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45160da5-5cea-475f-8aeb-15f2f93352c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85aa940-18bb-456c-addc-ddca10c54be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e213fc09-1720-4947-873b-ec15597ee0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ace569e-a952-48dd-b633-699fbb3c27fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## computes output shape for both convolutions and pooling layers\n",
    "def output_shape(in_dim,stride,padding,kernel,dilation=1):\n",
    "    out_dim = np.floor((in_dim + 2*padding - dilation*(kernel-1)-1)/stride+1).astype(int)\n",
    "    return out_dim\n",
    "\n",
    "def output_shape_transpose(in_dim,stride,padding,kernel,output_padding, dilation=1):\n",
    "    out_dim = (in_dim-1)*stride-2*padding+dilation*(kernel-1)+output_padding+1\n",
    "    return out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa54417-1d5d-4ce7-9081-6359c4c8c143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape(np.arange(5),stride=1,padding=0,kernel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c5ce73-6c2c-413c-a517-261aea0091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dilation(out_dim,in_dim,stride,padding,kernel,output_padding):\n",
    "    dilation = np.floor((out_dim-(in_dim-1)*stride+2*padding-output_padding-1)/(kernel-1))\n",
    "    new_dim  = output_shape_transpose(in_dim,stride,padding,kernel,output_padding, dilation)\n",
    "    if new_dim == out_dim:\n",
    "        pass\n",
    "    else:\n",
    "        output_padding = (out_dim-new_dim)\n",
    "    return dilation, output_padding\n",
    "\n",
    "def get_output_padding(in_dim,out_dim, stride,padding,kernel,dilation=1):\n",
    "    return out_dim-(in_dim-1)*stride+2*padding-dilation*(kernel-1)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d21fa279-be16-453d-b901-f76ed2774cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a878e81-e0a4-454a-80d5-0e80c0220cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCEncoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(FCEncoder, self).__init__()\n",
    "        if params['dim'] == '1D':\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "            \n",
    "        self.model = nn.ModuleList()\n",
    "    \n",
    "        self.model.append(nn.Flatten())\n",
    "        \n",
    "        current_dim = params['input_dim']**self.N*params['input_c']\n",
    "        \n",
    "        for ii in range(nparams['n_layers']):\n",
    "            \n",
    "            lin = nn.Linear(current_dim, nparams['out_sizes'][ii])\n",
    "            self.model.append(spec_norm(lin))\n",
    "            \n",
    "            current_dim      =  nparams['out_sizes'][ii]\n",
    "            \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm(current_dim,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)\n",
    "            \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "            \n",
    "            dropout = nn.Dropout(nparams['dropout_rate'][ii])\n",
    "            self.model.append(dropout)\n",
    "        \n",
    "        lin = nn.Linear(current_dim,params['latent_dim'])\n",
    "        self.model.append(spec_norm(lin))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "            print(x.shape)\n",
    "            x = l(x)\n",
    "            print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099a6bc8-dc0e-4e46-957c-39e20f75fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        if params['dim'] == '1D':\n",
    "            self.conv = nn.Conv1d\n",
    "            self.pool = nn.AdaptiveMaxPool1d#nn.MaxPool1d\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.conv = nn.Conv2d\n",
    "            self.pool = nn.AdaptiveMaxPool2d\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "            \n",
    "        self.model = nn.ModuleList()\n",
    "    \n",
    "        current_channels   = params['input_c']\n",
    "        current_dim        = params['input_dim']\n",
    "        self.out_dims      = []\n",
    "        \n",
    "        for ii in range(nparams['n_layers']):\n",
    "            \n",
    "            conv = self.conv(current_channels, nparams['out_channels'][ii], nparams['kernel_sizes'][ii], nparams['strides'][ii], nparams['paddings'][ii])\n",
    "            self.out_dims.append(current_dim)\n",
    "            self.model.append(spec_norm(conv))\n",
    "            \n",
    "            current_channels =  nparams['out_channels'][ii]\n",
    "            current_dim      =  output_shape(current_dim, nparams['strides'][ii], nparams['paddings'][ii],nparams['kernel_sizes'][ii])\n",
    "            \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm([current_channels]+[current_dim]*self.N,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)\n",
    "                \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "            \n",
    "            pool = self.pool([current_dim//nparams['scale_facs'][ii]]*self.N)\n",
    "            self.model.append(pool)\n",
    "            \n",
    "            current_dim = current_dim//nparams['scale_facs'][ii]\n",
    "\n",
    "        self.final_dim = current_dim\n",
    "        self.final_c   = current_channels\n",
    "        \n",
    "        self.model.append(nn.Flatten())\n",
    "        current_shape = current_channels*current_dim**self.N\n",
    "        linear        = nn.Linear(current_shape,params['latent_dim'])\n",
    "        self.model.append(spec_norm(linear))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "            print(x.shape)\n",
    "            x = l(x)\n",
    "            print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8773f4e-9331-4073-ba73-beb8a765c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        \n",
    "        if params['dim'] == '1D':\n",
    "            self.conv = nn.ConvTranspose1d\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.conv = nn.ConvTranspose2d\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "        \n",
    "        self.pool   = nn.Upsample\n",
    "        \n",
    "        self.model  = nn.ModuleList()\n",
    "        \n",
    "        final_shape = nparams['final_c']*nparams['final_dim']**self.N\n",
    "    \n",
    "        self.model.append(nn.Flatten())\n",
    "        lin         = nn.Linear(params['latent_dim'],final_shape)\n",
    "        self.model.append(spec_norm(lin))\n",
    "\n",
    "        if params['dim'] == '1D':\n",
    "            self.model.append(Reshape((-1, nparams['final_c'],nparams['final_dim'])))\n",
    "        else:\n",
    "            self.model.append(Reshape((-1, nparams['final_c'],nparams['final_dim'],nparams['final_dim'])))\n",
    "                              \n",
    "        current_dim      = nparams['final_dim']\n",
    "        current_channels = nparams['final_c']\n",
    "            \n",
    "        for jj in range(1,nparams['n_layers']+1):\n",
    "            ii = nparams['n_layers'] - jj \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "                  \n",
    "            upsample    = nn.Upsample(scale_factor=nparams['scale_facs'][ii])\n",
    "            self.model.append(upsample)\n",
    "            current_dim = current_dim*nparams['scale_facs'][ii]\n",
    "                              \n",
    "            output_padding = get_output_padding(current_dim,nparams['out_dims'][ii],nparams['strides'][ii],nparams['paddings'][ii],nparams['kernel_sizes'][ii],dilation=1)\n",
    "            conv           = self.conv(current_channels, nparams['out_channels'][ii], kernel_size=nparams['kernel_sizes'][ii], stride=nparams['strides'][ii], padding=nparams['paddings'][ii], output_padding=output_padding)\n",
    "            self.model.append(spec_norm(conv))\n",
    "            \n",
    "            current_channels = nparams['out_channels'][ii]\n",
    "            current_dim      = output_shape_transpose(current_dim, stride=nparams['strides'][ii], padding=nparams['paddings'][ii],kernel=nparams['kernel_sizes'][ii],output_padding=output_padding)\n",
    "                \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm([current_channels]+[current_dim]*self.N,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)    \n",
    "                \n",
    "        \n",
    "        conv = self.conv(current_channels, 1, kernel_size=1, stride=1)\n",
    "        self.model.append(spec_norm(conv))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "            print(x.shape)\n",
    "            x = l(x)\n",
    "            print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1326674-3b3b-4775-9a54-7de19ac99cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCDecoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(FCDecoder, self).__init__()\n",
    "        if params['dim'] == '1D':\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "            \n",
    "        self.model = nn.ModuleList()\n",
    "    \n",
    "        self.model.append(nn.Flatten())\n",
    "        \n",
    "        current_dim = params['latent_dim']\n",
    "        \n",
    "        for jj in range(1,nparams['n_layers']+1):\n",
    "            ii = nparams['n_layers'] - jj \n",
    "            \n",
    "            lin = nn.Linear(current_dim, nparams['out_sizes'][ii])\n",
    "            self.model.append(spec_norm(lin))\n",
    "            \n",
    "            current_dim      =  nparams['out_sizes'][ii]\n",
    "            \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm(current_dim,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)\n",
    "                \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "            \n",
    "            dropout = nn.Dropout(nparams['dropout_rate'][ii])\n",
    "            self.model.append(dropout)\n",
    "        \n",
    "        lin = nn.Linear(current_dim,params['input_dim']**self.N*params['input_c'])\n",
    "        self.model.append(spec_norm(lin))\n",
    "        \n",
    "        self.model.append(Reshape([-1]+[params['input_c']]+[params['input_dim']]*self.N))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bcb7620-3c76-4891-80f9-61b62d31c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, params, network_params_enc, network_params_dec):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        if params['encoder_type'] == 'conv':\n",
    "            self.encoder = ConvEncoder(params, network_params_enc)\n",
    "            network_params_enc['out_dims']  = self.encoder.out_dims\n",
    "            network_params_enc['final_dim'] = self.encoder.final_dim\n",
    "            network_params_enc['final_c']   = self.encoder.final_c\n",
    "        elif params['encoder_type'] == 'fc':\n",
    "            self.encoder = FCEncoder(params, network_params_enc)\n",
    "        else:\n",
    "            raise Exception('invalid encoder type')\n",
    "            \n",
    "        if params['decoder_type'] == 'conv':\n",
    "            self.decoder = ConvDecoder(params, network_params_dec)\n",
    "        elif params['decoder_type'] == 'fc':\n",
    "            self.decoder = FCDecoder(params, network_params_dec)\n",
    "        else:\n",
    "            raise Exception('invalid decoder type')\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cb2599a-f4ab-4cfd-b54e-6f51cdadfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers     = 3\n",
    "out_channels = [2,4,8]\n",
    "kernel_sizes = [2,4,2]\n",
    "### stride,padding,kernel; [1,0,1] is identity\n",
    "#pooling_layers = [[1,0,1], [1,0,2]]\n",
    "scale_facs   = [2,2,1] \n",
    "paddings     = [0,0,0]\n",
    "strides      = [2,4,2]\n",
    "layer_norm   = [True,True,True]\n",
    "dropout_rate = [0.,0.,0.]\n",
    "spec_norm    = True\n",
    "dim          = '2D'\n",
    "activations  = ['ReLU', 'ReLU','ReLU']\n",
    "latent_dim   = 4\n",
    "input_c      = 1 \n",
    "input_dim    = 1000\n",
    "encoder_type = 'conv'\n",
    "decoder_type = 'conv'\n",
    "affine       = False\n",
    "out_sizes    = [256,128,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45c28651-e623-4d21-9038-12ece17fbd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params      = {'input_c': input_c, 'input_dim': input_dim, 'latent_dim': latent_dim, 'encoder_type': encoder_type, 'decoder_type': decoder_type, 'dim': dim}\n",
    "conv_network_params = {'n_layers': n_layers, 'out_channels': out_channels, 'kernel_sizes': kernel_sizes, 'scale_facs': scale_facs, 'paddings': paddings,\\\n",
    "                       'strides': strides,'activations': activations, 'spec_norm': spec_norm, 'dropout_rate':dropout_rate, 'layer_norm': layer_norm, 'affine': affine}\n",
    "fc_network_params   = {'n_layers': n_layers, 'out_sizes': out_sizes,'activations': activations, 'spec_norm': spec_norm, 'dropout_rate':dropout_rate, \\\n",
    "                       'layer_norm': layer_norm, 'affine': affine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1a95980-c3a4-4de6-901f-ce91aae482fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = Autoencoder(general_params, conv_network_params, conv_network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d7ec4ed-be9b-43c6-b1d4-e483e534190d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): ConvEncoder(\n",
       "    (model): ModuleList(\n",
       "      (0): Conv2d(1, 2, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm((2, 500, 500), eps=1e-05, elementwise_affine=False)\n",
       "      (2): ReLU()\n",
       "      (3): AdaptiveMaxPool2d(output_size=[250, 250])\n",
       "      (4): Conv2d(2, 4, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (5): LayerNorm((4, 62, 62), eps=1e-05, elementwise_affine=False)\n",
       "      (6): ReLU()\n",
       "      (7): AdaptiveMaxPool2d(output_size=[31, 31])\n",
       "      (8): Conv2d(4, 8, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (9): LayerNorm((8, 15, 15), eps=1e-05, elementwise_affine=False)\n",
       "      (10): ReLU()\n",
       "      (11): AdaptiveMaxPool2d(output_size=[15, 15])\n",
       "      (12): Flatten(start_dim=1, end_dim=-1)\n",
       "      (13): Linear(in_features=1800, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (model): ModuleList(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=4, out_features=1800, bias=True)\n",
       "      (2): Reshape()\n",
       "      (3): ReLU()\n",
       "      (4): Upsample(scale_factor=1.0, mode=nearest)\n",
       "      (5): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2), output_padding=(1, 1))\n",
       "      (6): LayerNorm((8, 31, 31), eps=1e-05, elementwise_affine=False)\n",
       "      (7): ReLU()\n",
       "      (8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (9): ConvTranspose2d(8, 4, kernel_size=(4, 4), stride=(4, 4), output_padding=(2, 2))\n",
       "      (10): LayerNorm((4, 250, 250), eps=1e-05, elementwise_affine=False)\n",
       "      (11): ReLU()\n",
       "      (12): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (13): ConvTranspose2d(4, 2, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (14): LayerNorm((2, 1000, 1000), eps=1e-05, elementwise_affine=False)\n",
       "      (15): ConvTranspose2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5298e3f4-45de-49d6-b096-2c701b05a439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1000, 1000])\n",
      "torch.Size([1, 2, 500, 500])\n",
      "torch.Size([1, 2, 500, 500])\n",
      "torch.Size([1, 2, 500, 500])\n",
      "torch.Size([1, 2, 500, 500])\n",
      "torch.Size([1, 2, 500, 500])\n",
      "torch.Size([1, 2, 500, 500])\n",
      "torch.Size([1, 2, 250, 250])\n",
      "torch.Size([1, 2, 250, 250])\n",
      "torch.Size([1, 4, 62, 62])\n",
      "torch.Size([1, 4, 62, 62])\n",
      "torch.Size([1, 4, 62, 62])\n",
      "torch.Size([1, 4, 62, 62])\n",
      "torch.Size([1, 4, 62, 62])\n",
      "torch.Size([1, 4, 62, 62])\n",
      "torch.Size([1, 4, 31, 31])\n",
      "torch.Size([1, 4, 31, 31])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 1800])\n",
      "torch.Size([1, 1800])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 1800])\n",
      "torch.Size([1, 1800])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 15, 15])\n",
      "torch.Size([1, 8, 31, 31])\n",
      "torch.Size([1, 8, 31, 31])\n",
      "torch.Size([1, 8, 31, 31])\n",
      "torch.Size([1, 8, 31, 31])\n",
      "torch.Size([1, 8, 31, 31])\n",
      "torch.Size([1, 8, 31, 31])\n",
      "torch.Size([1, 8, 62, 62])\n",
      "torch.Size([1, 8, 62, 62])\n",
      "torch.Size([1, 4, 250, 250])\n",
      "torch.Size([1, 4, 250, 250])\n",
      "torch.Size([1, 4, 250, 250])\n",
      "torch.Size([1, 4, 250, 250])\n",
      "torch.Size([1, 4, 250, 250])\n",
      "torch.Size([1, 4, 250, 250])\n",
      "torch.Size([1, 4, 500, 500])\n",
      "torch.Size([1, 4, 500, 500])\n",
      "torch.Size([1, 2, 1000, 1000])\n",
      "torch.Size([1, 2, 1000, 1000])\n",
      "torch.Size([1, 2, 1000, 1000])\n",
      "torch.Size([1, 2, 1000, 1000])\n",
      "torch.Size([1, 1, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "data =  torch.randn(1,1,1000,1000).to('cuda')\n",
    "\n",
    "\n",
    "res = AE.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9175fd50-35ec-416a-8f8e-21ff06de672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1000, 1000])\n",
      "torch.Size([2, 2, 500, 500])\n",
      "torch.Size([2, 2, 500, 500])\n",
      "torch.Size([2, 2, 500, 500])\n",
      "torch.Size([2, 2, 500, 500])\n",
      "torch.Size([2, 2, 500, 500])\n",
      "torch.Size([2, 2, 500, 500])\n",
      "torch.Size([2, 2, 250, 250])\n",
      "torch.Size([2, 2, 250, 250])\n",
      "torch.Size([2, 4, 62, 62])\n",
      "torch.Size([2, 4, 62, 62])\n",
      "torch.Size([2, 4, 62, 62])\n",
      "torch.Size([2, 4, 62, 62])\n",
      "torch.Size([2, 4, 62, 62])\n",
      "torch.Size([2, 4, 62, 62])\n",
      "torch.Size([2, 4, 31, 31])\n",
      "torch.Size([2, 4, 31, 31])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 1800])\n",
      "torch.Size([2, 1800])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 1800])\n",
      "torch.Size([2, 1800])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 15, 15])\n",
      "torch.Size([2, 8, 31, 31])\n",
      "torch.Size([2, 8, 31, 31])\n",
      "torch.Size([2, 8, 31, 31])\n",
      "torch.Size([2, 8, 31, 31])\n",
      "torch.Size([2, 8, 31, 31])\n",
      "torch.Size([2, 8, 31, 31])\n",
      "torch.Size([2, 8, 62, 62])\n",
      "torch.Size([2, 8, 62, 62])\n",
      "torch.Size([2, 4, 250, 250])\n",
      "torch.Size([2, 4, 250, 250])\n",
      "torch.Size([2, 4, 250, 250])\n",
      "torch.Size([2, 4, 250, 250])\n",
      "torch.Size([2, 4, 250, 250])\n",
      "torch.Size([2, 4, 250, 250])\n",
      "torch.Size([2, 4, 500, 500])\n",
      "torch.Size([2, 4, 500, 500])\n",
      "torch.Size([2, 2, 1000, 1000])\n",
      "torch.Size([2, 2, 1000, 1000])\n",
      "torch.Size([2, 2, 1000, 1000])\n",
      "torch.Size([2, 2, 1000, 1000])\n",
      "torch.Size([2, 1, 1000, 1000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 2, 500, 500]              10\n",
      "         LayerNorm-2          [-1, 2, 500, 500]               0\n",
      "              ReLU-3          [-1, 2, 500, 500]               0\n",
      " AdaptiveMaxPool2d-4          [-1, 2, 250, 250]               0\n",
      "            Conv2d-5            [-1, 4, 62, 62]             132\n",
      "         LayerNorm-6            [-1, 4, 62, 62]               0\n",
      "              ReLU-7            [-1, 4, 62, 62]               0\n",
      " AdaptiveMaxPool2d-8            [-1, 4, 31, 31]               0\n",
      "            Conv2d-9            [-1, 8, 15, 15]             136\n",
      "        LayerNorm-10            [-1, 8, 15, 15]               0\n",
      "             ReLU-11            [-1, 8, 15, 15]               0\n",
      "AdaptiveMaxPool2d-12            [-1, 8, 15, 15]               0\n",
      "          Flatten-13                 [-1, 1800]               0\n",
      "           Linear-14                    [-1, 4]           7,204\n",
      "      ConvEncoder-15                    [-1, 4]               0\n",
      "          Flatten-16                    [-1, 4]               0\n",
      "           Linear-17                 [-1, 1800]           9,000\n",
      "          Reshape-18            [-1, 8, 15, 15]               0\n",
      "             ReLU-19            [-1, 8, 15, 15]               0\n",
      "         Upsample-20            [-1, 8, 15, 15]               0\n",
      "  ConvTranspose2d-21            [-1, 8, 31, 31]             264\n",
      "        LayerNorm-22            [-1, 8, 31, 31]               0\n",
      "             ReLU-23            [-1, 8, 31, 31]               0\n",
      "         Upsample-24            [-1, 8, 62, 62]               0\n",
      "  ConvTranspose2d-25          [-1, 4, 250, 250]             516\n",
      "        LayerNorm-26          [-1, 4, 250, 250]               0\n",
      "             ReLU-27          [-1, 4, 250, 250]               0\n",
      "         Upsample-28          [-1, 4, 500, 500]               0\n",
      "  ConvTranspose2d-29        [-1, 2, 1000, 1000]              34\n",
      "        LayerNorm-30        [-1, 2, 1000, 1000]               0\n",
      "  ConvTranspose2d-31        [-1, 1, 1000, 1000]               3\n",
      "      ConvDecoder-32        [-1, 1, 1000, 1000]               0\n",
      "================================================================\n",
      "Total params: 17,299\n",
      "Trainable params: 17,299\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.81\n",
      "Forward/backward pass size (MB): 72.44\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 76.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(AE, data.shape[1::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75e495-7dfb-49e8-95be-0c13fd32051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cef670-353f-4641-9698-5b3a307bc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ba6d8-1b4c-428f-9de3-f5233606c5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
