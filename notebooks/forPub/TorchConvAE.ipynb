{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f65200-2db4-4ddb-9069-06f59a58b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1a59e5-b64c-4e4c-a96b-8ff0e6d7d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f5d9ec3-a68a-40fa-94c2-01e1e527c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "45160da5-5cea-475f-8aeb-15f2f93352c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85aa940-18bb-456c-addc-ddca10c54be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e213fc09-1720-4947-873b-ec15597ee0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ace569e-a952-48dd-b633-699fbb3c27fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## computes output shape for both convolutions and pooling layers\n",
    "def output_shape(in_dim,stride,padding,kernel,dilation=1):\n",
    "    out_dim = np.floor((in_dim + 2*padding - dilation*(kernel-1)-1)/stride+1).astype(int)\n",
    "    return out_dim\n",
    "\n",
    "def output_shape_transpose(in_dim,stride,padding,kernel,output_padding, dilation=1):\n",
    "    out_dim = (in_dim-1)*stride-2*padding+dilation*(kernel-1)+output_padding+1\n",
    "    return out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa54417-1d5d-4ce7-9081-6359c4c8c143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape(np.arange(5),stride=1,padding=0,kernel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "81c5ce73-6c2c-413c-a517-261aea0091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dilation(out_dim,in_dim,stride,padding,kernel,output_padding):\n",
    "    dilation = np.floor((out_dim-(in_dim-1)*stride+2*padding-output_padding-1)/(kernel-1))\n",
    "    new_dim  = output_shape_transpose(in_dim,stride,padding,kernel,output_padding, dilation)\n",
    "    if new_dim == out_dim:\n",
    "        pass\n",
    "    else:\n",
    "        output_padding = (out_dim-new_dim)\n",
    "    return dilation, output_padding\n",
    "\n",
    "def get_output_padding(in_dim,out_dim, stride,padding,kernel,dilation=1):\n",
    "    return out_dim-(in_dim-1)*stride+2*padding-dilation*(kernel-1)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d21fa279-be16-453d-b901-f76ed2774cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2a878e81-e0a4-454a-80d5-0e80c0220cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCEncoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(FCEncoder, self).__init__()\n",
    "        if params['dim'] == '1D':\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "            \n",
    "        self.model = nn.ModuleList()\n",
    "    \n",
    "        self.model.append(nn.Flatten())\n",
    "        \n",
    "        current_dim = params['input_dim']**self.N*params['input_c']\n",
    "        \n",
    "        for ii in range(nparams['n_layers']):\n",
    "            \n",
    "            lin = nn.Linear(current_dim, nparams['out_sizes'][ii])\n",
    "            self.model.append(spec_norm(lin))\n",
    "            \n",
    "            current_dim      =  nparams['out_sizes'][ii]\n",
    "            \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm(current_dim,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)\n",
    "            \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "            \n",
    "            dropout = nn.Dropout(nparams['dropout_rate'][ii])\n",
    "            self.model.append(dropout)\n",
    "        \n",
    "        lin = nn.Linear(current_dim,params['latent_dim'])\n",
    "        self.model.append(spec_norm(lin))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "099a6bc8-dc0e-4e46-957c-39e20f75fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        if params['dim'] == '1D':\n",
    "            self.conv = nn.Conv1d\n",
    "            self.pool = nn.AdaptiveMaxPool1d#nn.MaxPool1d\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.conv = nn.Conv2d\n",
    "            self.pool = nn.AdaptiveMaxPool2d\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "            \n",
    "        self.model = nn.ModuleList()\n",
    "    \n",
    "        current_channels   = params['input_c']\n",
    "        current_dim        = params['input_dim']\n",
    "        self.out_dims      = []\n",
    "        \n",
    "        for ii in range(nparams['n_layers']):\n",
    "            \n",
    "            conv = self.conv(current_channels, nparams['out_channels'][ii], nparams['kernel_sizes'][ii], nparams['strides'][ii], nparams['paddings'][ii])\n",
    "            self.out_dims.append(current_dim)\n",
    "            self.model.append(spec_norm(conv))\n",
    "            \n",
    "            current_channels =  nparams['out_channels'][ii]\n",
    "            current_dim      =  output_shape(current_dim, nparams['strides'][ii], nparams['paddings'][ii],nparams['kernel_sizes'][ii])\n",
    "            \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm([current_channels]+[current_dim]*self.N,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)\n",
    "                \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "            \n",
    "            pool = self.pool([current_dim//nparams['scale_facs'][ii]]*self.N)\n",
    "            self.model.append(pool)\n",
    "            \n",
    "            current_dim = current_dim//nparams['scale_facs'][ii]\n",
    "\n",
    "        self.final_dim = current_dim\n",
    "        self.final_c   = current_channels\n",
    "        \n",
    "        self.model.append(nn.Flatten())\n",
    "        current_shape = current_channels*current_dim**self.N\n",
    "        linear        = nn.Linear(current_shape,params['latent_dim'])\n",
    "        self.model.append(spec_norm(linear))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "\n",
    "            x = l(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b8773f4e-9331-4073-ba73-beb8a765c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        \n",
    "        if params['dim'] == '1D':\n",
    "            self.conv = nn.ConvTranspose1d\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.conv = nn.ConvTranspose2d\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "        \n",
    "        self.pool   = nn.Upsample\n",
    "        \n",
    "        self.model  = nn.ModuleList()\n",
    "        \n",
    "        final_shape = nparams['final_c']*nparams['final_dim']**self.N\n",
    "    \n",
    "        self.model.append(nn.Flatten())\n",
    "        lin         = nn.Linear(params['latent_dim'],final_shape)\n",
    "        self.model.append(spec_norm(lin))\n",
    "\n",
    "        if params['dim'] == '1D':\n",
    "            self.model.append(Reshape((-1, nparams['final_c'],nparams['final_dim'])))\n",
    "        else:\n",
    "            self.model.append(Reshape((-1, nparams['final_c'],nparams['final_dim'],nparams['final_dim'])))\n",
    "                              \n",
    "        current_dim      = nparams['final_dim']\n",
    "        current_channels = nparams['final_c']\n",
    "            \n",
    "        for jj in range(1,nparams['n_layers']+1):\n",
    "            ii = nparams['n_layers'] - jj \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "                  \n",
    "            upsample    = nn.Upsample(scale_factor=nparams['scale_facs'][ii])\n",
    "            self.model.append(upsample)\n",
    "            current_dim = current_dim*nparams['scale_facs'][ii]\n",
    "                              \n",
    "            output_padding = get_output_padding(current_dim,nparams['out_dims'][ii],nparams['strides'][ii],nparams['paddings'][ii],nparams['kernel_sizes'][ii],dilation=1)\n",
    "            conv           = self.conv(current_channels, nparams['out_channels'][ii], kernel_size=nparams['kernel_sizes'][ii], stride=nparams['strides'][ii], padding=nparams['paddings'][ii], output_padding=output_padding)\n",
    "            self.model.append(spec_norm(conv))\n",
    "            \n",
    "            current_channels = nparams['out_channels'][ii]\n",
    "            current_dim      = output_shape_transpose(current_dim, stride=nparams['strides'][ii], padding=nparams['paddings'][ii],kernel=nparams['kernel_sizes'][ii],output_padding=output_padding)\n",
    "                \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm([current_channels]+[current_dim]*self.N,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)    \n",
    "                \n",
    "        \n",
    "        conv = self.conv(current_channels, 1, kernel_size=1, stride=1)\n",
    "        self.model.append(spec_norm(conv))\n",
    "        \n",
    "        if nparams['image_data']: \n",
    "            self.model.append(getattr(nn, 'Sigmoid')())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a1326674-3b3b-4775-9a54-7de19ac99cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCDecoder(nn.Module):\n",
    "    def __init__(self, params, nparams):\n",
    "        super(FCDecoder, self).__init__()\n",
    "        if params['dim'] == '1D':\n",
    "            self.N    = 1\n",
    "        elif params['dim'] == '2D':\n",
    "            self.N    = 2\n",
    "        else:\n",
    "            raise Exception(\"Invalid data dimensionality (must be either 1D or 2D).\")\n",
    "            \n",
    "            \n",
    "        if nparams['spec_norm']:\n",
    "            spec_norm = nn.utils.spectral_norm\n",
    "        else:\n",
    "            spec_norm = nn.Identity()\n",
    "            \n",
    "        self.model = nn.ModuleList()\n",
    "    \n",
    "        self.model.append(nn.Flatten())\n",
    "        \n",
    "        current_dim = params['latent_dim']\n",
    "        \n",
    "        for jj in range(1,nparams['n_layers']+1):\n",
    "            ii = nparams['n_layers'] - jj \n",
    "            \n",
    "            lin = nn.Linear(current_dim, nparams['out_sizes'][ii])\n",
    "            self.model.append(spec_norm(lin))\n",
    "            \n",
    "            current_dim      =  nparams['out_sizes'][ii]\n",
    "            \n",
    "            if nparams['layer_norm'][ii]:\n",
    "                norm = nn.LayerNorm(current_dim,elementwise_affine=nparams['affine'])\n",
    "                self.model.append(norm)\n",
    "                \n",
    "            gate = getattr(nn, nparams['activations'][ii])()\n",
    "            self.model.append(gate)\n",
    "            \n",
    "            dropout = nn.Dropout(nparams['dropout_rate'][ii])\n",
    "            self.model.append(dropout)\n",
    "        \n",
    "        lin = nn.Linear(current_dim,params['input_dim']**self.N*params['input_c'])\n",
    "        self.model.append(spec_norm(lin))\n",
    "        \n",
    "        if nparams['image_data']: \n",
    "            self.model.append(getattr(nn, 'Sigmoid')())\n",
    "        \n",
    "        self.model.append(Reshape([-1]+[params['input_c']]+[params['input_dim']]*self.N))\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.model):\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a6b7aae5-9771-4a32-99f7-823bc046a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, loc, batchsize):\n",
    "    \n",
    "    if data in dir(datasets):\n",
    "        dataset = getattr(datasets,data)\n",
    "    \n",
    "        training_data = dataset(root=loc,train=True,download=True,transform=ToTensor())\n",
    "\n",
    "        valid_data    = dataset(root=loc,train=False,download=True,transform=ToTensor())\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    train_dataloader = DataLoader(training_data, batch_size=batchsize, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0bcb7620-3c76-4891-80f9-61b62d31c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, params, dparams, nparams_enc, nparams_dec, tparams):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        if params['encoder_type'] == 'conv':\n",
    "            self.encoder = ConvEncoder(params, nparams_enc)\n",
    "            nparams_enc['out_dims']  = self.encoder.out_dims\n",
    "            nparams_enc['final_dim'] = self.encoder.final_dim\n",
    "            nparams_enc['final_c']   = self.encoder.final_c\n",
    "        elif params['encoder_type'] == 'fc':\n",
    "            self.encoder = FCEncoder(params, nparams_enc)\n",
    "        else:\n",
    "            raise Exception('invalid encoder type')\n",
    "            \n",
    "        if params['decoder_type'] == 'conv':\n",
    "            self.decoder = ConvDecoder(params, nparams_dec)\n",
    "        elif params['decoder_type'] == 'fc':\n",
    "            self.decoder = FCDecoder(params, n_dec)\n",
    "        else:\n",
    "            raise Exception('invalid decoder type')\n",
    "        \n",
    "        self.optimizer = getattr(optim, tparams['optimizer'])\n",
    "        self.optimizer = self.optimizer(self.parameters(),tparams['initial_lr'])\n",
    "        \n",
    "        self.scheduler = partial(getattr(torch.optim.lr_scheduler, tparams['scheduler']),self.optimizer)\n",
    "        self.scheduler = self.scheduler(**tparams['scheduler_params'])\n",
    "        \n",
    "        self.criterion = getattr(nn, tparams['criterion'])()\n",
    "        \n",
    "        self.train_loader, self.valid_loader = get_data(dparams['dataset'],dparams['loc'],tparams['batchsize'])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def update_lr(self,lr):\n",
    "    \n",
    "        self.optimizer = getattr(optim, tparams['optimizer'])\n",
    "        self.optimizer  = self.optimizer(self.parameters(),lr)\n",
    "        \n",
    "        self.scheduler = partial(getattr(torch.optim.lr_scheduler, tparams['scheduler']),self.optimizer)\n",
    "        self.scheduler = self.scheduler(**tparams['scheduler_params'])\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def update_scheduler(self,scheduler, scheduler_params):\n",
    "        \n",
    "        self.scheduler = partial(getattr(torch.optim.lr_scheduler, scheduler),self.optimizer)\n",
    "        self.scheduler = self.scheduler(**scheduler_params)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def update_optimizer(self,optimizer):\n",
    "        \n",
    "        self.optimizer = getattr(optim, optimizer)\n",
    "        self.optimizer  = self.optimizer(self.parameters(),tparams['initial_lr'])\n",
    "        \n",
    "        self.scheduler = partial(getattr(torch.optim.lr_scheduler, tparams['scheduler']),self.optimizer)\n",
    "        self.scheduler = self.scheduler(**tparams['scheduler_params'])\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def train(self, nepochs):\n",
    "        losses  = []\n",
    "        for epoch in range(nepochs):\n",
    "            for (data, _) in self.train_loader:\n",
    "                data = data.to(device)\n",
    "                recon = self.forward(data)\n",
    "                loss = self.criterion(recon, data)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                losses.append(loss)\n",
    "            self.scheduler.step()\n",
    "            print(f'epoch: {epoch:d}, training loss: {loss:.4e}')\n",
    "        return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3cb2599a-f4ab-4cfd-b54e-6f51cdadfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers     = 3\n",
    "out_channels = [8,8,8]\n",
    "kernel_sizes = [4,2,2]\n",
    "### stride,padding,kernel; [1,0,1] is identity\n",
    "#pooling_layers = [[1,0,1], [1,0,2]]\n",
    "scale_facs   = [1,1,1] \n",
    "paddings     = [0,0,0]\n",
    "strides      = [2,1,1]\n",
    "layer_norm   = [True,True,True]\n",
    "dropout_rate = [0.,0.,0.]\n",
    "spec_norm    = True\n",
    "dim          = '2D'\n",
    "activations  = ['ReLU', 'ReLU','ReLU']\n",
    "latent_dim   = 4\n",
    "input_c      = 1 \n",
    "input_dim    = 28\n",
    "encoder_type = 'conv'\n",
    "decoder_type = 'conv'\n",
    "affine       = False\n",
    "out_sizes    = [256,128,64]\n",
    "image_data   = True\n",
    "\n",
    "nepochs       = 4\n",
    "batchsize     = 128\n",
    "initial_lr    = 1e-3\n",
    "\n",
    "optimizer     = 'Adam'\n",
    "criterion     = 'MSELoss'\n",
    "\n",
    "scheduler     = 'ExponentialLR'\n",
    "scheduler_params = {'gamma':0.95}\n",
    "\n",
    "dataset       = 'MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "45c28651-e623-4d21-9038-12ece17fbd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params      = {'input_c': input_c, 'input_dim': input_dim, 'latent_dim': latent_dim, 'encoder_type': encoder_type, 'decoder_type': decoder_type, 'dim': dim}\n",
    "conv_network_params = {'n_layers': n_layers, 'out_channels': out_channels, 'kernel_sizes': kernel_sizes, 'scale_facs': scale_facs, 'paddings': paddings,\\\n",
    "                       'strides': strides,'activations': activations, 'spec_norm': spec_norm, 'dropout_rate':dropout_rate, 'layer_norm': layer_norm,\\\n",
    "                       'affine': affine,'image_data': image_data}\n",
    "fc_network_params   = {'n_layers': n_layers, 'out_sizes': out_sizes,'activations': activations, 'spec_norm': spec_norm, 'dropout_rate':dropout_rate, \\\n",
    "                       'layer_norm': layer_norm, 'affine': affine, 'image_data': image_data}\n",
    "\n",
    "training_params     = {'batchsize': batchsize, 'initial_lr': initial_lr, 'optimizer': optimizer, 'criterion': criterion, \\\n",
    "                       'scheduler': scheduler, 'scheduler_params':scheduler_params}\n",
    "data_params         = {'dataset':dataset, 'loc': '/global/cscratch1/sd/vboehm/Datasets'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b1a95980-c3a4-4de6-901f-ce91aae482fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = Autoencoder(general_params,data_params,conv_network_params, conv_network_params, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1af0f28d-bc4f-44f3-999d-97a04331095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(AE.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9604fb11-3562-4b6f-9bfd-c14bf8ef035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8d7ec4ed-be9b-43c6-b1d4-e483e534190d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): ConvEncoder(\n",
       "    (model): ModuleList(\n",
       "      (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (1): LayerNorm((8, 13, 13), eps=1e-05, elementwise_affine=False)\n",
       "      (2): ReLU()\n",
       "      (3): AdaptiveMaxPool2d(output_size=[13, 13])\n",
       "      (4): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (5): LayerNorm((8, 12, 12), eps=1e-05, elementwise_affine=False)\n",
       "      (6): ReLU()\n",
       "      (7): AdaptiveMaxPool2d(output_size=[12, 12])\n",
       "      (8): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (9): LayerNorm((8, 11, 11), eps=1e-05, elementwise_affine=False)\n",
       "      (10): ReLU()\n",
       "      (11): AdaptiveMaxPool2d(output_size=[11, 11])\n",
       "      (12): Flatten(start_dim=1, end_dim=-1)\n",
       "      (13): Linear(in_features=968, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (model): ModuleList(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=4, out_features=968, bias=True)\n",
       "      (2): Reshape()\n",
       "      (3): ReLU()\n",
       "      (4): Upsample(scale_factor=1.0, mode=nearest)\n",
       "      (5): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (6): LayerNorm((8, 12, 12), eps=1e-05, elementwise_affine=False)\n",
       "      (7): ReLU()\n",
       "      (8): Upsample(scale_factor=1.0, mode=nearest)\n",
       "      (9): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (10): LayerNorm((8, 13, 13), eps=1e-05, elementwise_affine=False)\n",
       "      (11): ReLU()\n",
       "      (12): Upsample(scale_factor=1.0, mode=nearest)\n",
       "      (13): ConvTranspose2d(8, 8, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (14): LayerNorm((8, 28, 28), eps=1e-05, elementwise_affine=False)\n",
       "      (15): ConvTranspose2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (16): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5298e3f4-45de-49d6-b096-2c701b05a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  torch.randn(1,1,28,28).to('cuda')\n",
    "\n",
    "\n",
    "res = AE.forward(train_features.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9175fd50-35ec-416a-8f8e-21ff06de672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 13, 13]             136\n",
      "         LayerNorm-2            [-1, 8, 13, 13]               0\n",
      "              ReLU-3            [-1, 8, 13, 13]               0\n",
      " AdaptiveMaxPool2d-4            [-1, 8, 13, 13]               0\n",
      "            Conv2d-5            [-1, 8, 12, 12]             264\n",
      "         LayerNorm-6            [-1, 8, 12, 12]               0\n",
      "              ReLU-7            [-1, 8, 12, 12]               0\n",
      " AdaptiveMaxPool2d-8            [-1, 8, 12, 12]               0\n",
      "            Conv2d-9            [-1, 8, 11, 11]             264\n",
      "        LayerNorm-10            [-1, 8, 11, 11]               0\n",
      "             ReLU-11            [-1, 8, 11, 11]               0\n",
      "AdaptiveMaxPool2d-12            [-1, 8, 11, 11]               0\n",
      "          Flatten-13                  [-1, 968]               0\n",
      "           Linear-14                    [-1, 4]           3,876\n",
      "      ConvEncoder-15                    [-1, 4]               0\n",
      "          Flatten-16                    [-1, 4]               0\n",
      "           Linear-17                  [-1, 968]           4,840\n",
      "          Reshape-18            [-1, 8, 11, 11]               0\n",
      "             ReLU-19            [-1, 8, 11, 11]               0\n",
      "         Upsample-20            [-1, 8, 11, 11]               0\n",
      "  ConvTranspose2d-21            [-1, 8, 12, 12]             264\n",
      "        LayerNorm-22            [-1, 8, 12, 12]               0\n",
      "             ReLU-23            [-1, 8, 12, 12]               0\n",
      "         Upsample-24            [-1, 8, 12, 12]               0\n",
      "  ConvTranspose2d-25            [-1, 8, 13, 13]             264\n",
      "        LayerNorm-26            [-1, 8, 13, 13]               0\n",
      "             ReLU-27            [-1, 8, 13, 13]               0\n",
      "         Upsample-28            [-1, 8, 13, 13]               0\n",
      "  ConvTranspose2d-29            [-1, 8, 28, 28]           1,032\n",
      "        LayerNorm-30            [-1, 8, 28, 28]               0\n",
      "  ConvTranspose2d-31            [-1, 1, 28, 28]               9\n",
      "          Sigmoid-32            [-1, 1, 28, 28]               0\n",
      "      ConvDecoder-33            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 10,949\n",
      "Trainable params: 10,949\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.33\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(AE, data.shape[1::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ba6d8-1b4c-428f-9de3-f5233606c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 5.5544e-02\n",
      "epoch: 1, loss: 4.6534e-02\n",
      "epoch: 2, loss: 4.4221e-02\n",
      "epoch: 3, loss: 4.2146e-02\n",
      "epoch: 4, loss: 3.5483e-02\n",
      "epoch: 5, loss: 3.9296e-02\n",
      "epoch: 6, loss: 3.6239e-02\n",
      "epoch: 7, loss: 3.8043e-02\n",
      "epoch: 8, loss: 3.4639e-02\n",
      "epoch: 9, loss: 3.9481e-02\n"
     ]
    }
   ],
   "source": [
    "AE.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53550d29-8ed1-4b73-9ae3-deea2f736500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835149dd-30bb-4173-9df0-c28c83290fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
