{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7a3ff4-6b29-4be5-bb5b-c9a630a2dfdf",
   "metadata": {},
   "source": [
    "### De-Amortize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7db77-3926-4359-bbf7-bb95e5e9edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ### De-Amortize\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "SMALL_SIZE =  14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "RUN             = '1'\n",
    "\n",
    "seeds           = {'1':5123, '2':879, '3':9981, '4': 20075, '5': 66, '6': 276, '7': 936664}\n",
    "\n",
    "conditional     = False\n",
    "cond_on         = 'type'\n",
    "\n",
    "root_model_data = '/global/cscratch1/sd/vboehm/Datasets/sdss/by_model/'\n",
    "root_models     = '/global/cscratch1/sd/vboehm/Models/SDSS_AE/'\n",
    "root_encoded    = '/global/cscratch1/sd/vboehm/Datasets/encoded/sdss/'\n",
    "root_decoded    = '/global/cscratch1/sd/vboehm/Datasets/decoded/sdss/'\n",
    "\n",
    "\n",
    "wlmin, wlmax    = (3388,8318)\n",
    "fixed_num_bins  = 1000\n",
    "min_SN          = 50\n",
    "min_z           = 0.1\n",
    "max_z           = 0.36\n",
    "label           = 'galaxies_quasars_bins%d_wl%d-%d'%(fixed_num_bins,wlmin,wlmax)\n",
    "label_          = label+'_minz%s_maxz%s_minSN%d'%(str(int(min_z*100)).zfill(3),str(int(max_z*100)).zfill(3),min_SN)\n",
    "label_2         = label_+'_10_fully_connected_mean_div'\n",
    "\n",
    "plotpath        = '/global/homes/v/vboehm/codes/SDSS_PAE/figures'\n",
    "\n",
    "\n",
    "if conditional:\n",
    "    label_2='conditional_%s'%cond_on+label_2\n",
    "    \n",
    "upsampling      = 'SMOTE'\n",
    "fac             = 10\n",
    "\n",
    "\n",
    "load_path = '/global/homes/v/vboehm/codes/SDSS_PAE/notebooks/'\n",
    "\n",
    "_,_,train_, le = pickle.load(open(os.path.join(root_model_data,'combined_%s.pkl'%label_),'rb'))\n",
    "_,_,encoded_train = np.load(os.path.join(root_encoded,'encoded_%s_RUN%s.npy'%(label_2,RUN)), allow_pickle=True)\n",
    "_,_,train, mean, std = np.load(os.path.join(root_decoded,'decoded_%s_RUN%s.npy'%(label_2,RUN)), allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "enc_weights = np.load(os.path.join(load_path,'encoder_weights.npy'), allow_pickle=True)\n",
    "dec_weights = np.load(os.path.join(load_path,'decoder_weights.npy'), allow_pickle=True)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "for ii in range(len(enc_weights)):\n",
    "    print(enc_weights[ii].shape)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "latent_dim      = 10\n",
    "lr_final        = 1.3e-05\n",
    "lr_init         = 7e-4\n",
    "out_features    = [1000,590]\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)  \n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seed):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(fixed_num_bins, out_features[0])\n",
    "        self.fc2 = nn.Linear(out_features[0],out_features[1])\n",
    "        self.fc3 = nn.Linear(out_features[1], latent_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc1(state))\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "encoder=Encoder(time.time()).to(device)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "encoder.fc1.weight.data=torch.from_numpy(np.transpose(enc_weights[0])).to(device)\n",
    "encoder.fc1.bias.data=torch.from_numpy(enc_weights[1]).to(device)\n",
    "encoder.fc2.weight.data=torch.from_numpy(np.transpose(enc_weights[2])).to(device)\n",
    "encoder.fc2.bias.data=torch.from_numpy(enc_weights[3]).to(device)\n",
    "encoder.fc3.weight.data=torch.from_numpy(np.transpose(enc_weights[4])).to(device)\n",
    "encoder.fc3.bias.data=torch.from_numpy(enc_weights[5]).to(device)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "pred = encoder.forward(torch.from_numpy(train_['spec'][:,:,0]).float().to(device))\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "pred.device\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder\"\"\"\n",
    "\n",
    "    def __init__(self, seed):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(latent_dim, out_features[1])\n",
    "        self.fc2 = nn.Linear(out_features[1],out_features[0])\n",
    "        self.fc3 = nn.Linear(out_features[0],fixed_num_bins)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc1(state))\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "decoder=Decoder(time.time()).to(device)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "decoder.fc1.weight.data=torch.from_numpy(np.transpose(dec_weights[0])).to(device)\n",
    "decoder.fc1.bias.data=torch.from_numpy(dec_weights[1]).to(device)\n",
    "decoder.fc2.weight.data=torch.from_numpy(np.transpose(dec_weights[2])).to(device)\n",
    "decoder.fc2.bias.data=torch.from_numpy(dec_weights[3]).to(device)\n",
    "decoder.fc3.weight.data=torch.from_numpy(np.transpose(dec_weights[4])).to(device)\n",
    "decoder.fc3.bias.data=torch.from_numpy(dec_weights[5]).to(device)\n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "for param in decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "dec = decoder.forward(pred)\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "z_init = torch.Tensor(np.squeeze(encoded_train)).to(device)\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "z = torch.autograd.Variable(torch.Tensor(np.squeeze(encoded_train)).to(device),requires_grad=True).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def neg_log_posterior(z,x,noise,mask,decoder, dens, class_, prior=False):\n",
    "    pred  = decoder.forward(z)\n",
    "    ll    = torch.sum(0.5*(pred-x)*(pred-x)*noise*mask,axis=1)\n",
    "    if prior:\n",
    "        ll = ll -dens(z, class_)\n",
    "    return torch.mean(ll,axis=0)\n",
    "\n",
    "\n",
    "sys.path.append('/global/u2/v/vboehm/codes/SIG_GIS/')\n",
    "from sig_gis import *\n",
    "from sig_gis.GIS import *\n",
    "\n",
    "\n",
    "model = torch.load(os.path.join(root_models,'conditional_SINF_%s_%s_%d_AE1'%(label_2,upsampling,fac)))\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam([z], lr=1e-2)\n",
    "\n",
    "\n",
    "num_iter = 2#int(len(z)/500)\n",
    "resid    = len(z)%500\n",
    "print(resid)\n",
    "\n",
    "a = time.time()\n",
    "neg_logs =[]\n",
    "zs = []\n",
    "#stepping through dataset\n",
    "for jj in range(2):\n",
    "    # minimization steps\n",
    "    for ii in range(70):\n",
    "        if ii>40:\n",
    "            for param_group in optim.param_groups:\n",
    "                param_group['lr'] = 1e-3\n",
    "        if jj<num_iter:\n",
    "            if 0<ii<30:\n",
    "                neg_log = neg_log_posterior(z[jj*500:(jj+1)*500],torch.from_numpy(np.squeeze(train_['spec'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['noise'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['mask'])[jj*500:(jj+1)*500]).to(device),decoder,model.evaluate_density, torch.from_numpy(train_['subclass'][jj*500:(jj+1)*500]).to(device),prior=False)\n",
    "            else:\n",
    "                neg_log = neg_log_posterior(z[jj*500:(jj+1)*500],torch.from_numpy(np.squeeze(train_['spec'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['noise'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['mask'])[jj*500:(jj+1)*500]).to(device),decoder,model.evaluate_density, torch.from_numpy(train_['subclass'][jj*500:(jj+1)*500]).to(device), prior=True)\n",
    "\n",
    "        else:\n",
    "            if 0<ii<30:\n",
    "                neg_log = neg_log_posterior(z[jj*500::],torch.from_numpy(np.squeeze(train_['spec'])[jj*500::]).to(device),torch.from_numpy(np.squeeze(train_['noise'])[jj*500::]).to(device),torch.from_numpy(np.squeeze(train_['mask'])[jj*500::]).to(device),decoder,model.evaluate_density, torch.from_numpy(train_['subclass'][jj*500::]).to(device),prior=False)\n",
    "            else:\n",
    "                neg_log = neg_log_posterior(z[jj*500::],torch.from_numpy(np.squeeze(train_['spec'])[jj*500::]).to(device),torch.from_numpy(np.squeeze(train_['noise'])[jj*500::]).to(device),torch.from_numpy(np.squeeze(train_['mask'])[jj*500::]).to(device),decoder,model.evaluate_density, torch.from_numpy(train_['subclass'][jj*500::]).to(device), prior=True)\n",
    "        optim.zero_grad()\n",
    "        neg_log.backward()\n",
    "        optim.step()\n",
    "        neg_logs.append(neg_log.cpu().detach().numpy())\n",
    "    zs.append(z[jj*500:(jj+1)*500].cpu().detach().numpy())\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "zs = np.reshape(np.asarray(zs),(-1,10))\n",
    "#np.save(os.path.join(root_encoded,'encoded_MAP_test_%s_RUN%s.npy'%(label_2,RUN)),zs)\n",
    "\n",
    "print((end -a)/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c5b8c3-0e3f-4391-a70e-228e87dd6b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366c1a0a-6cf1-429c-a0d5-defd579abd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8a6664-9c3c-4b82-b317-0f944a3094b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE =  14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869020de-4a15-46ab-ab7d-9c2f10c3e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN             = '1'\n",
    "\n",
    "seeds           = {'1':5123, '2':879, '3':9981, '4': 20075, '5': 66, '6': 276, '7': 936664}\n",
    "\n",
    "conditional     = False\n",
    "cond_on         = 'type'\n",
    "\n",
    "root_model_data = '/global/cscratch1/sd/vboehm/Datasets/sdss/by_model/'\n",
    "root_models     = '/global/cscratch1/sd/vboehm/Models/SDSS_AE/'\n",
    "root_encoded    = '/global/cscratch1/sd/vboehm/Datasets/encoded/sdss/'\n",
    "root_decoded    = '/global/cscratch1/sd/vboehm/Datasets/decoded/sdss/'\n",
    "\n",
    "\n",
    "wlmin, wlmax    = (3388,8318)\n",
    "fixed_num_bins  = 1000\n",
    "min_SN          = 50\n",
    "min_z           = 0.1\n",
    "max_z           = 0.36\n",
    "label           = 'galaxies_quasars_bins%d_wl%d-%d'%(fixed_num_bins,wlmin,wlmax)\n",
    "label_          = label+'_minz%s_maxz%s_minSN%d'%(str(int(min_z*100)).zfill(3),str(int(max_z*100)).zfill(3),min_SN)\n",
    "label_2         = label_+'_10_fully_connected_mean_div'\n",
    "\n",
    "plotpath        = '/global/homes/v/vboehm/codes/SDSS_PAE/figures'\n",
    "\n",
    "\n",
    "if conditional:\n",
    "    label_2='conditional_%s'%cond_on+label_2\n",
    "    \n",
    "upsampling      = 'SMOTE'\n",
    "fac             = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9645ff15-7680-4497-999c-410a768bfb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/v/vboehm/.conda/envs/pytorch/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_,valid_,test_,le = pickle.load(open(os.path.join(root_model_data,'combined_%s.pkl'%label_),'rb'))\n",
    "encoded_train, encoded_valid, encoded_test = np.load(os.path.join(root_encoded,'encoded_%s_RUN%s.npy'%(label_2,RUN)), allow_pickle=True)\n",
    "train, valid, test, mean, std = np.load(os.path.join(root_decoded,'decoded_%s_RUN%s.npy'%(label_2,RUN)), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156f9ab5-04f9-4c89-8daa-9d6ae080634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_weights = np.load('encoder_weights.npy', allow_pickle=True)\n",
    "dec_weights = np.load('decoder_weights.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc4a48b-df5d-4874-8d86-cb15d440e661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n",
      "(1000,)\n",
      "(1000, 590)\n",
      "(590,)\n",
      "(590, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for ii in range(len(enc_weights)):\n",
    "    print(enc_weights[ii].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7742d65e-0917-4bd0-b695-72a883e87377",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim      = 10\n",
    "lr_final        = 1.3e-05\n",
    "lr_init         = 7e-4\n",
    "out_features    = [1000,590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b312f9f4-ca3c-40d0-a032-36fa94b4b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b32829d-a09b-4d2d-8b26-96a78cc6e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seed):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(fixed_num_bins, out_features[0])\n",
    "        self.fc2 = nn.Linear(out_features[0],out_features[1])\n",
    "        self.fc3 = nn.Linear(out_features[1], latent_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc1(state))\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "encoder=Encoder(time.time()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0d81e71-5908-43cb-9b8f-c6c62fa82a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fc1.weight.data=torch.from_numpy(np.transpose(enc_weights[0])).to(device)\n",
    "encoder.fc1.bias.data=torch.from_numpy(enc_weights[1]).to(device)\n",
    "encoder.fc2.weight.data=torch.from_numpy(np.transpose(enc_weights[2])).to(device)\n",
    "encoder.fc2.bias.data=torch.from_numpy(enc_weights[3]).to(device)\n",
    "encoder.fc3.weight.data=torch.from_numpy(np.transpose(enc_weights[4])).to(device)\n",
    "encoder.fc3.bias.data=torch.from_numpy(enc_weights[5]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331ecf9c-5a43-4918-b9c5-d4b94db82763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = encoder.forward(torch.from_numpy(train_['spec'][:,:,0]).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "758bfc92-6cf0-449b-890b-cce5a1d830c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29650bd-f4d9-4dea-8208-ae85dec96a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder\"\"\"\n",
    "\n",
    "    def __init__(self, seed):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(latent_dim, out_features[1])\n",
    "        self.fc2 = nn.Linear(out_features[1],out_features[0])\n",
    "        self.fc3 = nn.Linear(out_features[0],fixed_num_bins)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc1(state))\n",
    "        x = torch.nn.LeakyReLU(negative_slope=0.3)(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "decoder=Decoder(time.time()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b045c457-1476-44ab-ad06-c0baf0f3b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.fc1.weight.data=torch.from_numpy(np.transpose(dec_weights[0])).to(device)\n",
    "decoder.fc1.bias.data=torch.from_numpy(dec_weights[1]).to(device)\n",
    "decoder.fc2.weight.data=torch.from_numpy(np.transpose(dec_weights[2])).to(device)\n",
    "decoder.fc2.bias.data=torch.from_numpy(dec_weights[3]).to(device)\n",
    "decoder.fc3.weight.data=torch.from_numpy(np.transpose(dec_weights[4])).to(device)\n",
    "decoder.fc3.bias.data=torch.from_numpy(dec_weights[5]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b67bb5c-4885-454a-b43e-2b54c26ff148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1edf2abf-0e5a-4747-ba70-b62a16a588f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = decoder.forward(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f22b45f7-8aa7-409e-a5b4-b923121098bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_init = torch.Tensor(np.squeeze(encoded_train)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5502bf01-fd48-402c-bad9-36651f3bc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.autograd.Variable(torch.Tensor(np.squeeze(encoded_train)).to(device),requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33a5372b-f9fc-4e0b-8d41-1a6ec4eb6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_posterior(z,x,noise,mask,decoder, dens, class_, prior=False):\n",
    "    pred  = decoder.forward(z)\n",
    "    ll    = torch.sum(0.5*(pred-x)*(pred-x)*noise*mask,axis=1)\n",
    "    if prior:\n",
    "        ll = ll -dens(z, class_)\n",
    "    return torch.mean(ll,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6864cfdd-d2c2-40cb-8765-4eb24938692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/global/u2/v/vboehm/codes/SIG_GIS/')\n",
    "from sig_gis import *\n",
    "from sig_gis.GIS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e34cec8-57c2-4258-9ea5-4a588abe98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(root_models,'conditional_SINF_%s_%s_%d_AE1'%(label_2,upsampling,fac)))\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eeb3c39e-08db-4d17-bc6d-e60d4fe0e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam([z], lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b7f0697d-5a4f-4805-889a-44b9c4cd63d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "568.8936066867742\n",
      "563.0592233470292\n",
      "561.8220430475985\n",
      "561.235402184114\n",
      "560.6292078741234\n",
      "560.0169584898983\n",
      "559.4918379761167\n",
      "559.0636817957812\n",
      "558.7036932938506\n",
      "558.3770510786653\n",
      "10\n",
      "558.0616825293624\n",
      "557.7584776637384\n",
      "557.4789212125698\n",
      "557.2329226686647\n",
      "557.0314399435201\n",
      "556.8562380323206\n",
      "556.6688485786419\n",
      "556.4706651450545\n",
      "556.2979158244719\n",
      "556.1617649585437\n",
      "20\n",
      "556.0384016660194\n",
      "555.9073609174055\n",
      "555.7706716981852\n",
      "555.644911568783\n",
      "555.5369902268005\n",
      "555.437177779751\n",
      "555.3373097646258\n",
      "555.2402599572752\n",
      "555.1495969699603\n",
      "555.0644880946152\n",
      "30\n",
      "563.2744658691438\n",
      "563.1917897257603\n",
      "563.0739602555844\n",
      "562.9346819797395\n",
      "562.7860590271636\n",
      "562.6381943229947\n",
      "562.4961113513822\n",
      "562.358535157655\n",
      "562.2243088516549\n",
      "562.09909230735\n",
      "40\n",
      "561.983274700259\n",
      "561.874405362947\n",
      "561.8629659336483\n",
      "561.85027310221\n",
      "561.8367102966263\n",
      "561.8226554638816\n",
      "561.8083418122113\n",
      "561.7939550345936\n",
      "561.7797074979188\n",
      "561.7657930553144\n",
      "50\n",
      "561.7520815082769\n",
      "561.7384156384447\n",
      "561.7247235416542\n",
      "561.7110781438056\n",
      "561.6974370160831\n",
      "561.6837881254687\n",
      "561.6701967190811\n",
      "561.6567523601246\n",
      "561.6434393878097\n",
      "561.6303354569401\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "neg_logs =[]\n",
    "zs = []\n",
    "for jj in range(1):\n",
    "    print(jj)\n",
    "    for ii in range(60):\n",
    "        if ii>40:\n",
    "            for param_group in optim.param_groups:\n",
    "                param_group['lr'] = 1e-3\n",
    "        if ii%10==0:\n",
    "            print(ii)\n",
    "        if jj<538:\n",
    "            if 0<ii<30:\n",
    "                neg_log = neg_log_posterior(z[jj*500:(jj+1)*500],torch.from_numpy(np.squeeze(train_['spec'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['noise'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['mask'])[jj*500:(jj+1)*500]).to(device),decoder,model.evaluate_density, torch.from_numpy(train_['subclass'][jj*500:(jj+1)*500]).to(device),prior=False)\n",
    "            else:\n",
    "                neg_log = neg_log_posterior(z[jj*500:(jj+1)*500],torch.from_numpy(np.squeeze(train_['spec'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['noise'])[jj*500:(jj+1)*500]).to(device),torch.from_numpy(np.squeeze(train_['mask'])[jj*500:(jj+1)*500]).to(device),decoder,model.evaluate_density, torch.from_numpy(train_['subclass'][jj*500:(jj+1)*500]).to(device), prior=True)\n",
    "\n",
    "        else:\n",
    "            neg_log = neg_log_posterior(z[jj*500::],torch.from_numpy(np.squeeze(train_['spec'])[jj*500::]).to(device),torch.from_numpy(np.squeeze(train_['noise'])[jj*500::]).to(device),torch.from_numpy(np.squeeze(train_['mask'])[jj*500::]).to(device),decoder,model.evaluate_density, torch.from_numpy(train_['subclass'][jj*500::]).to(device))            \n",
    "        optim.zero_grad()\n",
    "        neg_log.backward()\n",
    "        optim.step()\n",
    "        neg_logs.append(neg_log.cpu().detach().numpy())\n",
    "        print(neg_logs[-1])\n",
    "    zs.append(z.cpu().detach().numpy())\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "23906081-38a3-40cb-bb62-d268cf89277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = np.reshape(np.asarray(zs),(-1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1305ca3d-a1bf-4656-abac-176bd897f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(root_encoded,'encoded_MAP_train_%s_RUN%s.npy'%(label_2,RUN)),zs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c4dac92-794f-482c-94a6-45652daec5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.48136737956312"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end -a)/60/60*len(train_['spec'])/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c4549-9cc2-425a-8828-d0586029c4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
